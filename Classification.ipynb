{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerosene-vive/demoMAP/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ExbNueiSrQvr"
      },
      "source": [
        "## Text classification using Neural Networks\n",
        "\n",
        "The goal of this notebook is to learn to Machine Learning for text classification.\n",
        "\n",
        "However keep in mind:\n",
        "- Deep Learning can be better on text classification that simpler ML techniques, but only on very large datasets and well designed/tuned models.\n",
        "- We won't be using the most efficient (in terms of computing) techniques, as Keras is good for prototyping but rather inefficient for training small embedding models on text.\n",
        "- The following projects can replicate similar word embedding models much more efficiently: [word2vec](https://github.com/dav/word2vec) and [gensim's word2vec](https://radimrehurek.com/gensim/models/word2vec.html)   (self-supervised learning only), [fastText](https://github.com/facebookresearch/fastText) (both supervised and self-supervised learning), [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki) (supervised learning).\n",
        "- Plain shallow sparse TF-IDF bigrams features without any embedding and Logistic Regression or Multinomial Naive Bayes is often competitive in small to medium datasets.\n",
        "\n",
        "\n",
        "### Sentipolc 2016\n",
        "\n",
        "It is the intention of the organizers to promote the construction of a shared dataset for both Sentipolc and the Named Entity rEcognition and Linking in Italian Tweets (NEEL-IT) Evalita 2016 task. Indeed, interest in entity-liking in Twitter is gaining increasing attention, as well as aspect-based sentiment analysis. In a world where e-commerce is part of our everyday life and social media platforms are regarded as new channels for marketing and for fostering trust of potential customers, such great interest in opinion mining from Twitter isn’t surprising. In this scenario, it is crucial to be able to mine opinions about specific aspects of objects and named entities. Therefore, we believe that besides the traditional task on message-level polarity classification, in the future editions of Evalita special focus should be given to entity-based sentiment analysis.\n",
        "The use of common data for the Sentipolc and NEEL-IT is a first step towards the long-term goal of enabling participants to develop end-to-end system from entity linking to entity-based sentiment analysis. http://www.di.unito.it/~tutreeb/sentipolc-evalita16/data.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uksPu2sRrQvt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "e29a2bce-c0eb-4f5d-c518-09b7ad3ad9c7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "tot=pd.read_csv('eventsFixed.csv')\n",
        "tot.drop('id',inplace=True,axis=1)\n",
        "tot.drop('isOpen',inplace=True,axis=1)\n",
        "si =0\n",
        "no =0\n",
        "print('i fun e music: ',str(len(tot[(tot[ 'isMusic']==1) & (tot['fun'] ==1)])))\n",
        "print('i non corrispondenti: ', str(len(tot[(((tot[ 'isMusic']==0) & (tot['fun'] ==1))| ((tot[ 'isMusic']==1) & (tot['fun'] ==0)))])))\n",
        "train,test=train_test_split(tot,test_size=0.2)\n",
        "print('rapporto fun/notfun: ', train[train.fun == 1].shape[0]/train[train.fun == 0].shape[0])\n",
        "print('rapporto food/notfood: ', train[train.food == 1].shape[0]/train[train.food == 0].shape[0])\n",
        "print('rapporto culture/notculture: ', train[train.culture == 1].shape[0]/train[train.culture == 0].shape[0])\n",
        "print('rapporto music/notmusic: ', train[train.isMusic == 1].shape[0]/train[train.isMusic == 0].shape[0])\n",
        "#there are no events closedoor\n",
        "#print('rapporto open/notopen: ', train[train.isOpen == 1].shape[0]/train[train.isOpen == 0].shape[0])\n",
        "\n",
        "r=train.corr(method='pearson')\n",
        "\n",
        "# Print the result\n",
        "r\n",
        "\n",
        "#print('# eventi musicali sono classificati come divertenti: : ', train[train.isMusic == 1, train.fun == 1].shape[0])\n",
        "#print('rapporto (open + notopen)/idk: ', train[train.isMusic == 1].shape[0] + train[train.isMusic == 0].shape[0] / train[train.isMusic == -1].shape[0])\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i fun e music:  252\n",
            "i non corrispondenti:  1268\n",
            "i corispondenti fun e isMusic:  0\n",
            "i non corrispondenti:  0\n",
            "rapporto fun/notfun:  0.5927152317880795\n",
            "rapporto food/notfood:  0.5149606299212598\n",
            "rapporto culture/notculture:  1.6428571428571428\n",
            "rapporto music/notmusic:  0.5642276422764227\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              fun      food   culture   isMusic\n",
              "fun      1.000000 -0.291423  0.199359 -0.130466\n",
              "food    -0.291423  1.000000 -0.026110 -0.175720\n",
              "culture  0.199359 -0.026110  1.000000  0.242354\n",
              "isMusic -0.130466 -0.175720  0.242354  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20ca6917-b32f-47f8-b584-69158bc775e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fun</th>\n",
              "      <th>food</th>\n",
              "      <th>culture</th>\n",
              "      <th>isMusic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fun</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.291423</td>\n",
              "      <td>0.199359</td>\n",
              "      <td>-0.130466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>-0.291423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026110</td>\n",
              "      <td>-0.175720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>culture</th>\n",
              "      <td>0.199359</td>\n",
              "      <td>-0.026110</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.242354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isMusic</th>\n",
              "      <td>-0.130466</td>\n",
              "      <td>-0.175720</td>\n",
              "      <td>0.242354</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20ca6917-b32f-47f8-b584-69158bc775e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20ca6917-b32f-47f8-b584-69158bc775e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20ca6917-b32f-47f8-b584-69158bc775e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ukd0b5mrrQv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b2c945-f712-4298-e914-0564ad14193e"
      },
      "source": [
        "sample_idx = 1000\n",
        "print(train[\"text\"][sample_idx])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In diretta TV da Roma per tifare......\n",
            "Forza NAPOLI.....!!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "J2qz0burrQv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dae6a81-dd23-460a-df4e-f8031c13eebe"
      },
      "source": [
        "target_classes = train[\"fun\"]\n",
        "\n",
        "target_id = train[\"fun\"][sample_idx]\n",
        "print(\"Class of previous message:\", target_id)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class of previous message: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ZXRSh7XMrQwA"
      },
      "source": [
        "Here are all the possible classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4-ziROzGrQwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3128c041-b6d9-429e-8f40-61409e2853fa"
      },
      "source": [
        "target_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "7405    1\n",
              "7406    1\n",
              "7407    0\n",
              "7408    1\n",
              "7409    1\n",
              "Name: opos, Length: 7410, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FAsr1e6mrQwI"
      },
      "source": [
        "### Preprocessing text for the (supervised) CBOW model\n",
        "\n",
        "We will implement a simple classification model in Keras. Raw text requires (sometimes a lot of) preprocessing.\n",
        "\n",
        "The following cells uses Keras to preprocess text:\n",
        "- using a tokenizer. You may use different tokenizers (from scikit-learn, NLTK, custom Python function etc.). This converts the texts into sequences of indices representing the `20000` most frequent words\n",
        "- sequences have different lengths, so we pad them (add 0s at the end until the sequence is of length `1000`)\n",
        "- we convert the output classes as 1-hot encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "WO8Raa-CrQwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc861d20-3c7e-4ff6-c9b6-db8d8aa337f8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "MAX_NB_WORDS = 20000\n",
        "\n",
        "# get the raw text data\n",
        "texts_train = train[\"text\"]\n",
        "texts_test =test[\"text\"]\n",
        "\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS, char_level=False)\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/preprocessing/text.py:234: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21234 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "nuoLwWfsrQwP"
      },
      "source": [
        "Tokenized sequences are converted to list of token ids (with an integer code):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "scrolled": true,
        "id": "v14-T1htrQwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc85eba-4350-4930-8729-ec5d54a03ca9"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[557,\n",
              " 11,\n",
              " 1081,\n",
              " 14,\n",
              " 47,\n",
              " 651,\n",
              " 22,\n",
              " 6520,\n",
              " 4070,\n",
              " 111,\n",
              " 10,\n",
              " 904,\n",
              " 34,\n",
              " 33,\n",
              " 15,\n",
              " 1,\n",
              " 7,\n",
              " 5,\n",
              " 6,\n",
              " 6521,\n",
              " 47,\n",
              " 977]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "he3oRoNLrQwX"
      },
      "source": [
        "The tokenizer object stores a mapping (vocabulary) from word strings to token ids that can be inverted to reconstruct the original message (without formatting):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "HWv9H-y3rQwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3503c5-7055-4c65-fa0f-24ae220f0062"
      },
      "source": [
        "type(tokenizer.word_index), len(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, 21234)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7Whhbl7urQwd"
      },
      "source": [
        "index_to_word = dict((i, w) for w, i in tokenizer.word_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "r3Y-rvEkrQwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fb9d7a83-be1f-45ff-e2a5-0fc5d9dcc6cf"
      },
      "source": [
        "\" \".join([index_to_word[i] for i in sequences[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'intanto la partita per via nazionale si complica saccomanni dice che mica tutti sono mario monti http t co xptnz4x7 via linkiesta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XifL5FgKrQwl"
      },
      "source": [
        "Let's have a closer look at the tokenized sequences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Apr3ZqnhrQwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59a4341-ec8d-4f13-ccd7-c91de6a24a68"
      },
      "source": [
        "seq_lens = [len(s) for s in sequences]\n",
        "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
        "print(\"max length: %d\" % max(seq_lens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average length: 16.0\n",
            "max length: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "U6Hp4pXwrQwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "02f49eb1-c7c9-495f-923f-13e2da5e0673"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(seq_lens, bins=50);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GfCRWAGirQwv"
      },
      "source": [
        "Let's zoom on the distribution of regular sized posts. The vast majority of the posts have less than 30 symbols:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5W6QRDcprQw0"
      },
      "source": [
        "Let's truncate and pad all the sequences to 25 symbols to build the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3DC-Ysi-rQw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92cfcfc-06de-4999-c12f-0fe26d8f73c3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 25\n",
        "\n",
        "# pad sequences with 0s\n",
        "x_train = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "x_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
        "\n",
        "print('Shape of data tensor:', x_train.shape)\n",
        "print('Shape of data test tensor:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (7410, 25)\n",
            "Shape of data test tensor: (2000, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yij15CxGZxmE",
        "outputId": "2e39250f-0312-419e-8520-4a4ba2ed267b"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 557,   11, 1081,   14,   47,  651,   22, 6520, 4070,  111,   10,\n",
              "        904,   34,   33,   15,    1,    7,    5,    6, 6521,   47,  977,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "77rTAOV3rQw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e66a2a1-f7c5-4c00-88cd-a99c5971c84e"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = train[\"opos\"]\n",
        "y_test = test[\"opos\"]\n",
        "\n",
        "y_train = to_categorical(np.asarray(y_train))\n",
        "print('Shape of label tensor:', y_train.shape)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label tensor: (7410, 2)\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSeAYSbF2ku4",
        "outputId": "129134ae-c75f-46c7-9f92-eac648b4228b"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A simple ScikitLearn Model"
      ],
      "metadata": {
        "id": "8jrmILoGPQ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Download the models (1660MB)\n",
        "word2vec_model300 = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpEfOS3qPUtU",
        "outputId": "e42930d5-4232-424a-f90d-074088e0d002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_emb = []\n",
        "for sentence in x_train:\n",
        "  print('sentence')\n",
        "  print(sentence)\n",
        "  sent_emb = [0 for k in range(300)] \n",
        "  \n",
        "  num_tok = 0\n",
        "  for tok in sentence:\n",
        "    if tok != 0:\n",
        "      word=list(word_index.keys())[list(word_index.values()).index(tok)]\n",
        "      print('word: '+ word)\n",
        "      try:\n",
        "          emb = word2vec_model300.wv[word]\n",
        "          sent_emb = [x + y for x, y in zip(sent_emb, emb)]\n",
        "          num_tok = num_tok +1\n",
        "      except:\n",
        "          pass\n",
        "  if num_tok != 0:\n",
        "    final_sent_emb = [x / num_tok for x in sent_emb]         \n",
        "  x_train_emb.append(final_sent_emb)\n",
        "  \n",
        "\n",
        "x_train_emb = np.array(x_train_emb)\n",
        "print(type(x_train_emb))\n",
        "print(len(x_train_emb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xE65AbBKSggq",
        "outputId": "9274780d-66db-4712-c2f7-71841faff05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence\n",
            "[ 557   11 1081   14   47  651   22 6520 4070  111   10  904   34   33\n",
            "   15    1    7    5    6 6521   47  977    0    0    0]\n",
            "word: intanto\n",
            "word: la\n",
            "word: partita\n",
            "word: per\n",
            "word: via\n",
            "word: nazionale\n",
            "word: si\n",
            "word: complica\n",
            "word: saccomanni\n",
            "word: dice\n",
            "word: che\n",
            "word: mica\n",
            "word: tutti\n",
            "word: sono\n",
            "word: mario\n",
            "word: monti\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: xptnz4x7\n",
            "word: via\n",
            "word: linkiesta\n",
            "sentence\n",
            "[1183 1515 1516  487   15    1    7    5    6 6522   47 4071    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: false\n",
            "word: illusioni\n",
            "word: sgradevoli\n",
            "word: realtà\n",
            "word: mario\n",
            "word: monti\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: wommcits\n",
            "word: via\n",
            "word: addtoany\n",
            "sentence\n",
            "[1183 1515 1516  487 4072    3   15    1   62  387   24  208    7    5\n",
            "    6 6523 3013  292    0    0    0    0    0    0    0]\n",
            "word: false\n",
            "word: illusioni\n",
            "word: sgradevoli\n",
            "word: realtà\n",
            "word: editoriale\n",
            "word: di\n",
            "word: mario\n",
            "word: monti\n",
            "word: sul\n",
            "word: corriere\n",
            "word: della\n",
            "word: sera\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 2jpxx6jm\n",
            "word: rassegna\n",
            "word: stampa\n",
            "sentence\n",
            "[  15    1   66 3014  834    2 4073   14  283 4074   16 1082 6524    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: mario\n",
            "word: monti\n",
            "word: berlusconi\n",
            "word: risparmi\n",
            "word: all'italia\n",
            "word: il\n",
            "word: biasimo\n",
            "word: per\n",
            "word: aver\n",
            "word: causato\n",
            "word: un\n",
            "word: disastro\n",
            "word: mariomontipremier\n",
            "sentence\n",
            "[  15    1   66 3014  834    2 4073   14  283 4074   16 1082   20 2408\n",
            "    3 1184    8  585    7    5    6 6525    0    0    0]\n",
            "word: mario\n",
            "word: monti\n",
            "word: berlusconi\n",
            "word: risparmi\n",
            "word: all'italia\n",
            "word: il\n",
            "word: biasimo\n",
            "word: per\n",
            "word: aver\n",
            "word: causato\n",
            "word: un\n",
            "word: disastro\n",
            "word: i\n",
            "word: giudizi\n",
            "word: di\n",
            "word: usa\n",
            "word: e\n",
            "word: europa\n",
            "word: http\n",
            "word: t\n",
            "word: co\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-4c0a08443f8e>:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  emb = word2vec_model300.wv[word]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "word: tiritwittoio\n",
            "word: che\n",
            "word: poi\n",
            "word: cmq\n",
            "word: lavorare\n",
            "word: anche\n",
            "word: di\n",
            "word: sabato\n",
            "word: va\n",
            "word: bene\n",
            "word: con\n",
            "word: la\n",
            "word: crisi\n",
            "word: e\n",
            "word: il\n",
            "word: precariato\n",
            "word: pensiamo\n",
            "word: a\n",
            "word: chi\n",
            "word: nn\n",
            "word: ce\n",
            "word: l'ha\n",
            "word: un\n",
            "word: lavoro\n",
            "word: dignità\n",
            "sentence\n",
            "[  497 15608     9  2825    14  2745 15609     8  2156 15610   114    25\n",
            " 15611    39   588 15612    20     7     5     6 15613     0     0     0\n",
            "     0]\n",
            "word: juve\n",
            "word: paratici\n",
            "word: a\n",
            "word: brescia\n",
            "word: per\n",
            "word: el\n",
            "word: kaddouri\n",
            "word: e\n",
            "word: definire\n",
            "word: leali\n",
            "word: piace\n",
            "word: anche\n",
            "word: arcari\n",
            "word: come\n",
            "word: terzo\n",
            "word: portiere\n",
            "word: i\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: rbmtgnyz\n",
            "sentence\n",
            "[    2   134  6080    37 15614    30    17   173   909  4264    45     2\n",
            "   502     8 15615     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: 1\n",
            "word: maggio\n",
            "word: lo\n",
            "word: festeggio\n",
            "word: con\n",
            "word: grillo\n",
            "word: troppo\n",
            "word: contento\n",
            "word: stò\n",
            "word: tutto\n",
            "word: il\n",
            "word: resto\n",
            "word: e\n",
            "word: noiaaaa\n",
            "sentence\n",
            "[  154  1697    34    61  2259 15616   405 15617     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: forza\n",
            "word: seguite\n",
            "word: tutti\n",
            "word: questo\n",
            "word: fantastico\n",
            "word: directionerboy\n",
            "word: gt\n",
            "word: ivanlofrano\n",
            "sentence\n",
            "[ 6094    17 15618   414 15619  1719 15620    54  2222     7     5     6\n",
            " 15621     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: luxuria\n",
            "word: grillo\n",
            "word: «omofobo»\n",
            "word: vendola\n",
            "word: «lui\n",
            "word: sintomo\n",
            "word: degrado»\n",
            "word: italia\n",
            "word: l'unità\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 25jpqhrj\n",
            "sentence\n",
            "[  108     3    45   724    82 15622   277    25    11    88 15623   179\n",
            "     7     5     6 15624     2    17  2366    57    13  6092     0     0\n",
            "     0]\n",
            "word: prima\n",
            "word: di\n",
            "word: tutto\n",
            "word: sapere\n",
            "word: poi\n",
            "word: votalo\n",
            "word: pure\n",
            "word: anche\n",
            "word: la\n",
            "word: lega\n",
            "word: votava\n",
            "word: bossi\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: as0ptxapdietro\n",
            "word: il\n",
            "word: grillo\n",
            "word: parlante\n",
            "word: chi\n",
            "word: è\n",
            "word: casaleggio\n",
            "sentence\n",
            "[    2 15625  1200    23  2340    35  5161   134     7     5     6 15626\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: mugello\n",
            "word: apre\n",
            "word: le\n",
            "word: porte\n",
            "word: alla\n",
            "word: formula\n",
            "word: 1\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: auufx8hu\n",
            "sentence\n",
            "[15627  2889 15628    21    46  1707   129     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: styron\n",
            "word: xx\n",
            "word: asdasdlfk\n",
            "word: ma\n",
            "word: grazie\n",
            "word: tesoro\n",
            "word: c\n",
            "sentence\n",
            "[15629 15630  5495    21   179   799    37  1501   383    62   617     3\n",
            "    17 15631     9    45   681    14   664   315    18  5879     0     0\n",
            "     0]\n",
            "word: saittello\n",
            "word: acdxer\n",
            "word: catwalkshow\n",
            "word: ma\n",
            "word: bossi\n",
            "word: infatti\n",
            "word: lo\n",
            "word: metto\n",
            "word: quasi\n",
            "word: sul\n",
            "word: piano\n",
            "word: di\n",
            "word: grillo\n",
            "word: sparate\n",
            "word: a\n",
            "word: tutto\n",
            "word: campo\n",
            "word: per\n",
            "word: prendere\n",
            "word: voti\n",
            "word: del\n",
            "word: popolino\n",
            "sentence\n",
            "[15632    14   154   966   966     2   291    13     2  5594 15633   775\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: unicornfuckery\n",
            "word: per\n",
            "word: forza\n",
            "word: v\n",
            "word: v\n",
            "word: il\n",
            "word: problema\n",
            "word: è\n",
            "word: il\n",
            "word: fuso\n",
            "word: orario\n",
            "word: ahah\n",
            "sentence\n",
            "[15634   168  3740     9   227   682    48  1227    45     2  1182    19\n",
            "  1307   556  6097 15635  5327  6098 15636  6099  1068  2983 15637     0\n",
            "     0]\n",
            "word: ehymalik\n",
            "word: niente\n",
            "word: ripenso\n",
            "word: a\n",
            "word: ieri\n",
            "word: ahahahah\n",
            "word: ho\n",
            "word: parlato\n",
            "word: tutto\n",
            "word: il\n",
            "word: pomeriggio\n",
            "word: in\n",
            "word: inglese\n",
            "word: ero\n",
            "word: stra\n",
            "word: fogata\n",
            "word: marò\n",
            "word: smile\n",
            "word: you're\n",
            "word: pretty\n",
            "word: my\n",
            "word: nick\n",
            "word: yo\n",
            "sentence\n",
            "[  219  2931 15638  1649 15639   144    17     9  1076    17   105   584\n",
            "    34    19   237  3969   314   461     0     0     0     0     0     0\n",
            "     0]\n",
            "word: elezioni\n",
            "word: amministrative\n",
            "word: dom\n",
            "word: 29\n",
            "word: apr\n",
            "word: beppe\n",
            "word: grillo\n",
            "word: a\n",
            "word: palermo\n",
            "word: grillo\n",
            "word: m5s\n",
            "word: m5stour\n",
            "word: tutti\n",
            "word: in\n",
            "word: piazza\n",
            "word: croci\n",
            "word: ore\n",
            "word: 18\n",
            "sentence\n",
            "[   25    17    60   323 15640  1403  1365 15641  1479  1756    25    30\n",
            "    11    96     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: anche\n",
            "word: grillo\n",
            "word: nel\n",
            "word: partito\n",
            "word: antieuro\n",
            "word: vecchia\n",
            "word: campagna\n",
            "word: reazionaria\n",
            "word: resta\n",
            "word: tale\n",
            "word: anche\n",
            "word: con\n",
            "word: la\n",
            "word: crisi\n",
            "sentence\n",
            "[ 1306  3987    84   219  2931   472 15642    17   144    17   105   584\n",
            "   210    34    20   141     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: comune\n",
            "word: messina\n",
            "word: alle\n",
            "word: elezioni\n",
            "word: amministrative\n",
            "word: 2013\n",
            "word: stravincerà\n",
            "word: grillo\n",
            "word: beppe\n",
            "word: grillo\n",
            "word: m5s\n",
            "word: m5stour\n",
            "word: fuori\n",
            "word: tutti\n",
            "word: i\n",
            "word: partiti\n",
            "sentence\n",
            "[   30    17   253    45   440     7     5     6 15643   392 15644  3897\n",
            "  1001     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: con\n",
            "word: grillo\n",
            "word: sembra\n",
            "word: tutto\n",
            "word: facile\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: w7hsg6a8\n",
            "word: blog\n",
            "word: politicapalazzo\n",
            "word: beppegrillo\n",
            "word: cultura\n",
            "sentence\n",
            "[    9    93  3473   482     8   158 15645     9   377     3    17    65\n",
            "    39   721     8  1547 15646    65     3    41     2   170  1166   105\n",
            "     0]\n",
            "word: a\n",
            "word: mio\n",
            "word: avviso\n",
            "word: giornalisti\n",
            "word: e\n",
            "word: politici\n",
            "word: sbagliano\n",
            "word: a\n",
            "word: parlare\n",
            "word: di\n",
            "word: grillo\n",
            "word: solo\n",
            "word: come\n",
            "word: populista\n",
            "word: e\n",
            "word: demagogo\n",
            "word: rischiano\n",
            "word: solo\n",
            "word: di\n",
            "word: fare\n",
            "word: il\n",
            "word: suo\n",
            "word: gioco\n",
            "word: m5s\n",
            "sentence\n",
            "[    2 15647 15648    10    44   164    83    23   356    64  3456     2\n",
            "   194     9  2355   121   711     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: tic\n",
            "word: dell'unfollow\n",
            "word: che\n",
            "word: ti\n",
            "word: parte\n",
            "word: quando\n",
            "word: le\n",
            "word: persone\n",
            "word: ancora\n",
            "word: rompono\n",
            "word: il\n",
            "word: cazzo\n",
            "word: a\n",
            "word: realemiskilla\n",
            "word: senza\n",
            "word: motivo\n",
            "sentence\n",
            "[15649    77    64    32  1835  1700   693     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ludobalu\n",
            "word: sei\n",
            "word: ancora\n",
            "word: da\n",
            "word: emma\n",
            "word: l'hai\n",
            "word: vista\n",
            "sentence\n",
            "[   32   144    17   274 15650    20   604  1380    24   508     7     5\n",
            "     6 15651     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: da\n",
            "word: beppe\n",
            "word: grillo\n",
            "word: agli\n",
            "word: ayatollah\n",
            "word: i\n",
            "word: migliori\n",
            "word: articoli\n",
            "word: della\n",
            "word: settimana\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: dwxtu5jv\n",
            "sentence\n",
            "[  25   73   33   19 6005  353    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: anche\n",
            "word: oggi\n",
            "word: sono\n",
            "word: in\n",
            "word: vacanza\n",
            "word: sapevatelo\n",
            "sentence\n",
            "[  137   765     9  3988 15652    50   141  3870     3  1384    98   368\n",
            " 15653   137    17   114   103  3989  2648     0     0     0     0     0\n",
            "     0]\n",
            "word: perchè\n",
            "word: mette\n",
            "word: a\n",
            "word: nudo\n",
            "word: l'incapacità\n",
            "word: dei\n",
            "word: partiti\n",
            "word: tradizionali\n",
            "word: di\n",
            "word: guidare\n",
            "word: l'italia\n",
            "word: “\n",
            "word: mikelealvarez\n",
            "word: perchè\n",
            "word: grillo\n",
            "word: piace\n",
            "word: ai\n",
            "word: piccoli\n",
            "word: imprenditori\n",
            "sentence\n",
            "[  11  252   24 1287   18 1368   63    2  729   51   17  111   45 1955\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: la\n",
            "word: faccia\n",
            "word: della\n",
            "word: giornalista\n",
            "word: del\n",
            "word: tg3\n",
            "word: dopo\n",
            "word: il\n",
            "word: servizio\n",
            "word: su\n",
            "word: grillo\n",
            "word: dice\n",
            "word: tutto\n",
            "word: brava\n",
            "sentence\n",
            "[   17     2   170  2334   342   721    69    37   381  3923  1100 15654\n",
            "    24    88  3169   119  5508   104 15655     0     0     0     0     0\n",
            "     0]\n",
            "word: grillo\n",
            "word: il\n",
            "word: suo\n",
            "word: linguaggio\n",
            "word: politico\n",
            "word: populista\n",
            "word: e'\n",
            "word: lo\n",
            "word: stesso\n",
            "word: utilizzato\n",
            "word: durante\n",
            "word: l'ascesa\n",
            "word: della\n",
            "word: lega\n",
            "word: inizi\n",
            "word: anni\n",
            "word: '90\n",
            "word: siamo\n",
            "word: daccapo\n",
            "sentence\n",
            "[15656    68    63     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: franceses\n",
            "word: me\n",
            "word: dopo\n",
            "sentence\n",
            "[15657    39   819   176    93     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xlovemyidol\n",
            "word: come\n",
            "word: stai\n",
            "word: amore\n",
            "word: mio\n",
            "sentence\n",
            "[   63    11   810 15658     2 15659    40  1455    23  5754   810  2798\n",
            "  5190   805   132   479     3 15660     7     5     6 15661     0     0\n",
            "     0]\n",
            "word: dopo\n",
            "word: la\n",
            "word: linea\n",
            "word: convenienza\n",
            "word: il\n",
            "word: gigante\n",
            "word: ci\n",
            "word: propone\n",
            "word: le\n",
            "word: banane\n",
            "word: linea\n",
            "word: rocco\n",
            "word: siffredi\n",
            "word: 25\n",
            "word: x\n",
            "word: 15\n",
            "word: di\n",
            "word: circonferenza\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ioxejvet\n",
            "sentence\n",
            "[  933  1469    13   201    11    52   184   500    19   806    35   143\n",
            "    81  1123    40    85    17     8    20   297  2370 15662     0     0\n",
            "     0]\n",
            "word: maurizio\n",
            "word: lupi\n",
            "word: è\n",
            "word: vero\n",
            "word: la\n",
            "word: politica\n",
            "word: deve\n",
            "word: stare\n",
            "word: in\n",
            "word: mezzo\n",
            "word: alla\n",
            "word: gente\n",
            "word: perché\n",
            "word: altrimenti\n",
            "word: ci\n",
            "word: sta\n",
            "word: grillo\n",
            "word: e\n",
            "word: i\n",
            "word: suoi\n",
            "word: falsi\n",
            "word: ideali\n",
            "sentence\n",
            "[    2   338   116   423  1406  3643  5243 15663    24 15664     3 15665\n",
            " 15666   105    17     7     5     6 15667     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: movimento\n",
            "word: 5\n",
            "word: stelle\n",
            "word: presenta\n",
            "word: interrogazione\n",
            "word: sull'\n",
            "word: appalto\n",
            "word: della\n",
            "word: discarica\n",
            "word: di\n",
            "word: poiatica\n",
            "word: iren\n",
            "word: m5s\n",
            "word: grillo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: fhqm5i0j\n",
            "sentence\n",
            "[ 2302 15668 15669 15670  2806     9  3858    34    20  2364     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ilaria\n",
            "word: todaro\n",
            "word: franz\n",
            "word: krahler\n",
            "word: riceve\n",
            "word: a\n",
            "word: luglio\n",
            "word: tutti\n",
            "word: i\n",
            "word: colori\n",
            "sentence\n",
            "[ 5312  5858   107    17  1478    26   240    54 15671    52  3577     1\n",
            "   144    17     7     5     6 15672     0     0     0     0     0     0\n",
            "     0]\n",
            "word: arrabbiati\n",
            "word: bipartisan\n",
            "word: così\n",
            "word: grillo\n",
            "word: arriverà\n",
            "word: al\n",
            "word: 10\n",
            "word: italia\n",
            "word: cirsi\n",
            "word: politica\n",
            "word: attualità\n",
            "word: monti\n",
            "word: beppe\n",
            "word: grillo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 6viwfyyi\n",
            "sentence\n",
            "[   14    68    13    16   131    21  2984    10    12   680    29   487\n",
            "   241    45    13   577    25    60  1316    40    33   142    23  6100\n",
            " 15673]\n",
            "word: per\n",
            "word: me\n",
            "word: è\n",
            "word: un\n",
            "word: grande\n",
            "word: ma\n",
            "word: ricordate\n",
            "word: che\n",
            "word: non\n",
            "word: esiste\n",
            "word: una\n",
            "word: realtà\n",
            "word: dove\n",
            "word: tutto\n",
            "word: è\n",
            "word: perfetto\n",
            "word: anche\n",
            "word: nel\n",
            "word: mov5stelle\n",
            "word: ci\n",
            "word: sono\n",
            "word: già\n",
            "word: le\n",
            "word: mele\n",
            "word: marce\n",
            "sentence\n",
            "[15674   370    22    40 15675   271   185  2896    46   228   775     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: fuckgravity\n",
            "word: ah\n",
            "word: si\n",
            "word: ci\n",
            "word: sbavo\n",
            "word: ogni\n",
            "word: giorno\n",
            "word: q\n",
            "word: grazie\n",
            "word: comunque\n",
            "word: ahah\n",
            "sentence\n",
            "[   63    17    48  1315    10    12    86   241    80    11   361    22\n",
            "  1442    11  1811     9   454    13   575     3   717 15676 15677     0\n",
            "     0]\n",
            "word: dopo\n",
            "word: grillo\n",
            "word: ho\n",
            "word: imparato\n",
            "word: che\n",
            "word: non\n",
            "word: sempre\n",
            "word: dove\n",
            "word: c'è\n",
            "word: la\n",
            "word: merda\n",
            "word: si\n",
            "word: sente\n",
            "word: la\n",
            "word: puzza\n",
            "word: a\n",
            "word: volte\n",
            "word: è\n",
            "word: profumo\n",
            "word: di\n",
            "word: soldi\n",
            "word: poveraitalia\n",
            "word: sivieroandrea\n",
            "sentence\n",
            "[    8    82    42   207    64  6101     2 15678   513   188  6102 15679\n",
            "    32  6103    21    12   200    11   358    13    38   459     3    68\n",
            "     0]\n",
            "word: e\n",
            "word: poi\n",
            "word: io\n",
            "word: devo\n",
            "word: ancora\n",
            "word: guardarmi\n",
            "word: il\n",
            "word: docu\n",
            "word: film\n",
            "word: sui\n",
            "word: doors\n",
            "word: narrato\n",
            "word: da\n",
            "word: morgan\n",
            "word: ma\n",
            "word: non\n",
            "word: ce\n",
            "word: la\n",
            "word: faccio\n",
            "word: è\n",
            "word: più\n",
            "word: forte\n",
            "word: di\n",
            "word: me\n",
            "sentence\n",
            "[ 257    9   34    8 3785    9   68   51  187    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: buongiorno\n",
            "word: a\n",
            "word: tutti\n",
            "word: e\n",
            "word: benvenuta\n",
            "word: a\n",
            "word: me\n",
            "word: su\n",
            "word: twitter\n",
            "sentence\n",
            "[  190    25     9  1391 15680    18   721     8    18  3697    17    52\n",
            "     7     5     6 15681     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: adesso\n",
            "word: anche\n",
            "word: a\n",
            "word: travaglio\n",
            "word: daranno\n",
            "word: del\n",
            "word: populista\n",
            "word: e\n",
            "word: del\n",
            "word: qualunquista\n",
            "word: grillo\n",
            "word: politica\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: bzan2pbd\n",
            "sentence\n",
            "[15682   535   660  3818    33     3    75  6104  6105  4935   272     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: leibelieber\n",
            "word: cmq\n",
            "word: piacere\n",
            "word: martina\n",
            "word: sono\n",
            "word: di\n",
            "word: roma\n",
            "word: what's\n",
            "word: your\n",
            "word: name\n",
            "word: xd\n",
            "sentence\n",
            "[   17    22  1779   277     3  2353    11   292    21    31    33   119\n",
            "    10    37   448 15683   740   265     2  2742    24  2014     0     0\n",
            "     0]\n",
            "word: grillo\n",
            "word: si\n",
            "word: permette\n",
            "word: pure\n",
            "word: di\n",
            "word: insultare\n",
            "word: la\n",
            "word: stampa\n",
            "word: ma\n",
            "word: se\n",
            "word: sono\n",
            "word: anni\n",
            "word: che\n",
            "word: lo\n",
            "word: stanno\n",
            "word: pompando\n",
            "word: manco\n",
            "word: fosse\n",
            "word: il\n",
            "word: salvatore\n",
            "word: della\n",
            "word: patria\n",
            "sentence\n",
            "[   69  1050    17    22  5927     2    97   179  2120     9   141     8\n",
            "  1421  1003  1030     8  1940    24    52   507   509 15684     0     0\n",
            "     0]\n",
            "word: e'\n",
            "word: ufficiale\n",
            "word: grillo\n",
            "word: si\n",
            "word: considera\n",
            "word: il\n",
            "word: nuovo\n",
            "word: bossi\n",
            "word: insulti\n",
            "word: a\n",
            "word: partiti\n",
            "word: e\n",
            "word: media\n",
            "word: demagogia\n",
            "word: dura\n",
            "word: e\n",
            "word: pura\n",
            "word: della\n",
            "word: politica\n",
            "word: vera\n",
            "word: neanche\n",
            "word: l'ombra\n",
            "sentence\n",
            "[15685 15686  1707    70    45    49     9    94     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xstyles\n",
            "word: ciaaao\n",
            "word: tesoro\n",
            "word: 3\n",
            "word: tutto\n",
            "word: bene\n",
            "word: a\n",
            "word: te\n",
            "sentence\n",
            "[15687  5634     2    87   323    24  1521    21    31    12 15688  2439\n",
            "     2   672     3  2730  1351    11  2628    17   135     0     0     0\n",
            "     0]\n",
            "word: youdem\n",
            "word: siii\n",
            "word: il\n",
            "word: pd\n",
            "word: partito\n",
            "word: della\n",
            "word: costituzione\n",
            "word: ma\n",
            "word: se\n",
            "word: non\n",
            "word: rispettano\n",
            "word: neppure\n",
            "word: il\n",
            "word: diritto\n",
            "word: di\n",
            "word: opinione\n",
            "word: vedi\n",
            "word: la\n",
            "word: vicenda\n",
            "word: grillo\n",
            "word: napolitano\n",
            "sentence\n",
            "[   46    14  3990 15689    19   252    94    78    33 15690     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: grazie\n",
            "word: per\n",
            "word: avermi\n",
            "word: tossito\n",
            "word: in\n",
            "word: faccia\n",
            "word: te\n",
            "word: ne\n",
            "word: sono\n",
            "word: grato\n",
            "sentence\n",
            "[ 144   17    8   31   17  265  526  406 1246   24   52    8   34   53\n",
            "  206  158   33   20 1871    0    0    0    0    0    0]\n",
            "word: beppe\n",
            "word: grillo\n",
            "word: e\n",
            "word: se\n",
            "word: grillo\n",
            "word: fosse\n",
            "word: l'unica\n",
            "word: persona\n",
            "word: seria\n",
            "word: della\n",
            "word: politica\n",
            "word: e\n",
            "word: tutti\n",
            "word: gli\n",
            "word: altri\n",
            "word: politici\n",
            "word: sono\n",
            "word: i\n",
            "word: pagliacci\n",
            "sentence\n",
            "[225 208   9  34   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: buona\n",
            "word: sera\n",
            "word: a\n",
            "word: tutti\n",
            "sentence\n",
            "[  270    44    48    43  1687   348   348 15691   498   598     7     5\n",
            "     6 15692     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ok\n",
            "word: ti\n",
            "word: ho\n",
            "word: fatto\n",
            "word: pubblicità\n",
            "word: u\n",
            "word: u\n",
            "word: ileniahilary\n",
            "word: live\n",
            "word: on\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: dwxwgdwi\n",
            "sentence\n",
            "[   17  1859    11   205  1695  5387   364   134     2  2095   110  2120\n",
            "     8  1683   132 15693 15694    70    41    11  1449     0     0     0\n",
            "     0]\n",
            "word: grillo\n",
            "word: guardate\n",
            "word: la\n",
            "word: sua\n",
            "word: strategia\n",
            "word: comunicativa\n",
            "word: punto\n",
            "word: 1\n",
            "word: il\n",
            "word: nemico\n",
            "word: 2\n",
            "word: insulti\n",
            "word: e\n",
            "word: urla\n",
            "word: x\n",
            "word: coinvolgimento\n",
            "word: emotivo\n",
            "word: 3\n",
            "word: fare\n",
            "word: la\n",
            "word: vittima\n",
            "sentence\n",
            "[  179    17    12  3115   315    35    88   123  2335  3411     8 15695\n",
            "    11    88   253 15696    19  1087    51  1448 15697     0     0     0\n",
            "     0]\n",
            "word: bossi\n",
            "word: grillo\n",
            "word: non\n",
            "word: ruba\n",
            "word: voti\n",
            "word: alla\n",
            "word: lega\n",
            "word: tra\n",
            "word: diamanti\n",
            "word: case\n",
            "word: e\n",
            "word: tanzania\n",
            "word: la\n",
            "word: lega\n",
            "word: sembra\n",
            "word: maggiormente\n",
            "word: in\n",
            "word: difficoltà\n",
            "word: su\n",
            "word: altre\n",
            "word: ruberie\n",
            "sentence\n",
            "[ 1498   213 15698    23   217    49    27  3336     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: love\n",
            "word: far\n",
            "word: away\n",
            "word: le\n",
            "word: voglio\n",
            "word: bene\n",
            "word: mi\n",
            "word: mancava\n",
            "sentence\n",
            "[   57 15699    20  2913     9    17     8   765    45    60 15700  3846\n",
            "    58    12  2004    11    52  5210    58    13    16  1287   304     0\n",
            "     0]\n",
            "word: chi\n",
            "word: paragona\n",
            "word: i\n",
            "word: pirati\n",
            "word: a\n",
            "word: grillo\n",
            "word: e\n",
            "word: mette\n",
            "word: tutto\n",
            "word: nel\n",
            "word: calderone\n",
            "word: dell'antipolitica\n",
            "word: o\n",
            "word: non\n",
            "word: conosce\n",
            "word: la\n",
            "word: politica\n",
            "word: tedesca\n",
            "word: o\n",
            "word: è\n",
            "word: un\n",
            "word: giornalista\n",
            "word: italiano\n",
            "sentence\n",
            "[ 5690 15701 15702 15703    19  4399    55  1801   210    21    11    71\n",
            "    13   797    62    93  2351     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: benny\n",
            "word: feilhaber's\n",
            "word: beautiful\n",
            "word: profile\n",
            "word: in\n",
            "word: hd\n",
            "word: fa\n",
            "word: brutto\n",
            "word: fuori\n",
            "word: ma\n",
            "word: la\n",
            "word: vita\n",
            "word: è\n",
            "word: bellissima\n",
            "word: sul\n",
            "word: mio\n",
            "word: divano\n",
            "sentence\n",
            "[15704 15705    62  3747    24  2871    48   759 15706    91   872   278\n",
            "    14  1791    19  1776     8  5646    23 15707    35 15708     0     0\n",
            "     0]\n",
            "word: eantiga\n",
            "word: massifont\n",
            "word: sul\n",
            "word: diario\n",
            "word: della\n",
            "word: giulia\n",
            "word: ho\n",
            "word: scritto\n",
            "word: munafò\n",
            "word: ad\n",
            "word: esempio\n",
            "word: giusto\n",
            "word: per\n",
            "word: restare\n",
            "word: in\n",
            "word: tema\n",
            "word: e\n",
            "word: lanciare\n",
            "word: le\n",
            "word: frecciate\n",
            "word: alla\n",
            "word: bisi\n",
            "sentence\n",
            "[15709   875  2737  3991     8  5611    19   806    35   447    50  1586\n",
            "    59    81    61   142    37   235     0     0     0     0     0     0\n",
            "     0]\n",
            "word: antonicont\n",
            "word: aspetta\n",
            "word: dovrebbero\n",
            "word: ballare\n",
            "word: e\n",
            "word: cantare\n",
            "word: in\n",
            "word: mezzo\n",
            "word: alla\n",
            "word: camera\n",
            "word: dei\n",
            "word: deputati\n",
            "word: no\n",
            "word: perché\n",
            "word: questo\n",
            "word: già\n",
            "word: lo\n",
            "word: fanno\n",
            "sentence\n",
            "[   63  3861   120   535   202   160   132   532    95    37  6107   259\n",
            "    40    28 15711     9   325     8   192    28 15712     2   753   348\n",
            "   348]\n",
            "word: dopo\n",
            "word: sanremo\n",
            "word: d\n",
            "word: cmq\n",
            "word: sì\n",
            "word: era\n",
            "word: x\n",
            "word: colpa\n",
            "word: mia\n",
            "word: lo\n",
            "word: ammetto\n",
            "word: lei\n",
            "word: ci\n",
            "word: ha\n",
            "word: trovati\n",
            "word: a\n",
            "word: letto\n",
            "word: e\n",
            "word: nn\n",
            "word: ha\n",
            "word: retto\n",
            "word: il\n",
            "word: colpo\n",
            "word: u\n",
            "word: u\n",
            "sentence\n",
            "[  105   269     2   364    24   722    17    74  6108   254     2    43\n",
            "   439     7     5     6 15713    47   345     0     0     0     0     0\n",
            "     0]\n",
            "word: m5s\n",
            "word: finalmente\n",
            "word: il\n",
            "word: punto\n",
            "word: della\n",
            "word: situazione\n",
            "word: grillo\n",
            "word: contro\n",
            "word: maciste\n",
            "word: –\n",
            "word: il\n",
            "word: fatto\n",
            "word: quotidiano\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: kwu5u6j5\n",
            "word: via\n",
            "word: fattoquotidiano\n",
            "sentence\n",
            "[15714     8    44  2260    64     3    38    81    77    16  1979  6109\n",
            " 15715     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: gagashotdog\n",
            "word: e\n",
            "word: ti\n",
            "word: stimo\n",
            "word: ancora\n",
            "word: di\n",
            "word: più\n",
            "word: perché\n",
            "word: sei\n",
            "word: un\n",
            "word: directioner\n",
            "word: boy\n",
            "word: uù\n",
            "sentence\n",
            "[   17     8   179    88   160   154  3274 15716   105    69 15717   651\n",
            "  3290   136   103   262  6052    54     0     0     0     0     0     0\n",
            "     0]\n",
            "word: grillo\n",
            "word: e\n",
            "word: bossi\n",
            "word: lega\n",
            "word: era\n",
            "word: forza\n",
            "word: territoriale\n",
            "word: separatista\n",
            "word: m5s\n",
            "word: e'\n",
            "word: aggregatore\n",
            "word: nazionale\n",
            "word: generazionale\n",
            "word: fiducia\n",
            "word: ai\n",
            "word: giovani\n",
            "word: muoviti\n",
            "word: italia\n",
            "sentence\n",
            "[ 1453  1004    17    65    29 15718    10   701    41    57    28   216\n",
            "     3    16  1471   342  6018     9    61     4     0     0     0     0\n",
            "     0]\n",
            "word: polemica\n",
            "word: dipietro\n",
            "word: grillo\n",
            "word: solo\n",
            "word: una\n",
            "word: “strumentalizzazione\n",
            "word: che\n",
            "word: vuol\n",
            "word: fare\n",
            "word: chi\n",
            "word: ha\n",
            "word: paura\n",
            "word: di\n",
            "word: un\n",
            "word: progetto\n",
            "word: politico\n",
            "word: alternativo\n",
            "word: a\n",
            "word: questo\n",
            "word: governo\n",
            "sentence\n",
            "[ 1908  1024 15719    64    26   116    14 15720    26   116 15721    14\n",
            "    11  1905   102   988 15722    26  1398  1632     3 15723     0     0\n",
            "     0]\n",
            "word: equitalia\n",
            "word: giustizia\n",
            "word: aggio\n",
            "word: ancora\n",
            "word: al\n",
            "word: 5\n",
            "word: per\n",
            "word: centoconfermato\n",
            "word: al\n",
            "word: 5\n",
            "word: l'aggio\n",
            "word: per\n",
            "word: la\n",
            "word: gestione\n",
            "word: delle\n",
            "word: risorse\n",
            "word: intestate\n",
            "word: al\n",
            "word: fondo\n",
            "word: unico\n",
            "word: di\n",
            "word: giusti…\n",
            "sentence\n",
            "[15724    21   175   217    34  1503     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: acquaketa\n",
            "word: ma\n",
            "word: li\n",
            "word: voglio\n",
            "word: tutti\n",
            "word: arrivo\n",
            "sentence\n",
            "[  17  636  135 2030   50  141   54   50 1314    7    5    6 6110    1\n",
            "   88 3817  179    0    0    0    0    0    0    0    0]\n",
            "word: grillo\n",
            "word: attacca\n",
            "word: napolitano\n",
            "word: garante\n",
            "word: dei\n",
            "word: partiti\n",
            "word: italia\n",
            "word: dei\n",
            "word: dolori\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 4gi2hpaw\n",
            "word: monti\n",
            "word: lega\n",
            "word: legaladrona\n",
            "word: bossi\n",
            "sentence\n",
            "[   17    13    38  5833   190     3    83 15725    20   513  4603 15726\n",
            "    51   387     7     5     6 15727     0     0     0     0     0     0\n",
            "     0]\n",
            "word: grillo\n",
            "word: è\n",
            "word: più\n",
            "word: attore\n",
            "word: adesso\n",
            "word: di\n",
            "word: quando\n",
            "word: girava\n",
            "word: i\n",
            "word: film\n",
            "word: aldo\n",
            "word: grasso\n",
            "word: su\n",
            "word: corriere\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: x0wl9d1u\n",
            "sentence\n",
            "[15728    46  1390     9    63     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: marcoboccoli\n",
            "word: grazie\n",
            "word: marco\n",
            "word: a\n",
            "word: dopo\n",
            "sentence\n",
            "[ 153   17  636  135 2030   50  141   54   50 1314    7    5    6 6110\n",
            " 5610    1  105    4    0    0    0    0    0    0    0]\n",
            "word: video\n",
            "word: grillo\n",
            "word: attacca\n",
            "word: napolitano\n",
            "word: garante\n",
            "word: dei\n",
            "word: partiti\n",
            "word: italia\n",
            "word: dei\n",
            "word: dolori\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 4gi2hpaw\n",
            "word: omnibus\n",
            "word: monti\n",
            "word: m5s\n",
            "word: governo\n",
            "sentence\n",
            "[  105    17  1685  2223  1490     5     6 15729  2494    46     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: m5s\n",
            "word: grillo\n",
            "word: abc\n",
            "word: marcotravaglio\n",
            "word: https\n",
            "word: t\n",
            "word: co\n",
            "word: rkfpzfhjchiaro\n",
            "word: condivisibile\n",
            "word: grazie\n",
            "sentence\n",
            "[  368  2223    17    74  6108     7     5     6 15730    47   345   144\n",
            " 15731  1390    46    81    12   971  1189   186     0     0     0     0\n",
            "     0]\n",
            "word: “\n",
            "word: marcotravaglio\n",
            "word: grillo\n",
            "word: contro\n",
            "word: maciste\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ccdjou3d\n",
            "word: via\n",
            "word: fattoquotidiano\n",
            "word: beppe\n",
            "word: grillo”\n",
            "word: marco\n",
            "word: grazie\n",
            "word: perché\n",
            "word: non\n",
            "word: ricordo\n",
            "word: ste\n",
            "word: cose\n",
            "sentence\n",
            "[ 4701 15732 15733 15734  5520 15735     9    34     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: chicca\n",
            "word: 204\n",
            "word: bigincompiuta\n",
            "word: fposati\n",
            "word: nosapaid\n",
            "word: buondi\n",
            "word: a\n",
            "word: tutti\n",
            "sentence\n",
            "[15736    48    34    20  3992 15737  1358 15738    70     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: cciovato\n",
            "word: ho\n",
            "word: tutti\n",
            "word: i\n",
            "word: parenti\n",
            "word: paterni\n",
            "word: là\n",
            "word: shdfbvks\n",
            "word: 3\n",
            "sentence\n",
            "[ 1863    10 15739   265    16 15740 15741 15742    24  1001 15743     8\n",
            "   212    13    65    29 15744     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: pensavo\n",
            "word: che\n",
            "word: lalettura\n",
            "word: fosse\n",
            "word: un\n",
            "word: agguerrito\n",
            "word: think\n",
            "word: tank\n",
            "word: della\n",
            "word: cultura\n",
            "word: neoliberista\n",
            "word: e\n",
            "word: invece\n",
            "word: è\n",
            "word: solo\n",
            "word: una\n",
            "word: ciofeca\n",
            "sentence\n",
            "[15745 15746    28    11   205  6111    10    82  6112    25 15747     2\n",
            "  2614    13    16   243  1956     3 15748     0     0     0     0     0\n",
            "     0]\n",
            "word: aleauriemma\n",
            "word: l'estetica\n",
            "word: ha\n",
            "word: la\n",
            "word: sua\n",
            "word: importanza\n",
            "word: che\n",
            "word: poi\n",
            "word: sappiano\n",
            "word: anche\n",
            "word: spalancare\n",
            "word: il\n",
            "word: gas\n",
            "word: è\n",
            "word: un\n",
            "word: altro\n",
            "word: paio\n",
            "word: di\n",
            "word: maniche\n",
            "sentence\n",
            "[    9  1585 15749    35 15750     7     5     6 15751     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: a\n",
            "word: pranzo\n",
            "word: gnocchi\n",
            "word: alla\n",
            "word: gorgonzola\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: yabi2eks\n",
            "sentence\n",
            "[15752 15753  1508    46    14    11  3340     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: camilla7mariani\n",
            "word: caterinabosetti\n",
            "word: seriamente\n",
            "word: grazie\n",
            "word: per\n",
            "word: la\n",
            "word: pazienza\n",
            "sentence\n",
            "[   21    10   969    12    28    43 15754    35   252    50   820 15755\n",
            "    10 15756    65    19 15757     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ma\n",
            "word: che\n",
            "word: gol\n",
            "word: non\n",
            "word: ha\n",
            "word: fatto\n",
            "word: nocerino\n",
            "word: alla\n",
            "word: faccia\n",
            "word: dei\n",
            "word: ladri\n",
            "word: rubentini\n",
            "word: che\n",
            "word: segnano\n",
            "word: solo\n",
            "word: in\n",
            "word: fuorogioco\n",
            "sentence\n",
            "[ 5484    21   321    25    62   938 15758  1412 15759     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: formusictv\n",
            "word: ma\n",
            "word: siete\n",
            "word: anche\n",
            "word: sul\n",
            "word: digitale\n",
            "word: terrestre\n",
            "word: scusate\n",
            "word: l'ignoranza\n",
            "sentence\n",
            "[   21  1588   697    35   646    18   131 15760 15761 15762 15763 15764\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ma\n",
            "word: cos'è\n",
            "word: successo\n",
            "word: alla\n",
            "word: voce\n",
            "word: del\n",
            "word: grande\n",
            "word: alfredo\n",
            "word: atelalinea\n",
            "word: provenzali\n",
            "word: fiochissima\n",
            "word: tuttoilcalciominutoperminuto\n",
            "sentence\n",
            "[   46    25    31    12 15765   389    10    16  2545   115  5900 15766\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: grazie\n",
            "word: anche\n",
            "word: se\n",
            "word: non\n",
            "word: srà\n",
            "word: possibile\n",
            "word: che\n",
            "word: un\n",
            "word: cambiamento\n",
            "word: sia\n",
            "word: immediato\n",
            "word: robertosaviano\n",
            "sentence\n",
            "[   31     2   378    24   204    13 15767   162    16 15768   148     2\n",
            "  1721    13    37   381     7     5     6 15769     0     0     0     0\n",
            "     0]\n",
            "word: se\n",
            "word: il\n",
            "word: futuro\n",
            "word: della\n",
            "word: tv\n",
            "word: è\n",
            "word: freccero…\n",
            "word: meglio\n",
            "word: un\n",
            "word: carloconti\n",
            "word: tanto\n",
            "word: il\n",
            "word: livello\n",
            "word: è\n",
            "word: lo\n",
            "word: stesso\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: uqqyr8mt\n",
            "sentence\n",
            "[  154   375   104    86    30   223     7     5     6 15770     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: forza\n",
            "word: ragazzi\n",
            "word: siamo\n",
            "word: sempre\n",
            "word: con\n",
            "word: voi\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ssylduu2\n",
            "sentence\n",
            "[    7     5     6 15771    20   604 15772    24 15773  2985 15774     7\n",
            "     5     6 15775     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: vu42lgpn\n",
            "word: i\n",
            "word: migliori\n",
            "word: tiratori\n",
            "word: della\n",
            "word: ncaa\n",
            "word: larry\n",
            "word: bird\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 6qmx7gw3\n",
            "sentence\n",
            "[15776    12    22  2893    41 15777     3 15778  1048     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: claudiaandreavr\n",
            "word: non\n",
            "word: si\n",
            "word: puo\n",
            "word: fare\n",
            "word: indigestione\n",
            "word: di\n",
            "word: rugby\n",
            "word: impossibile\n",
            "sentence\n",
            "[   11  2331    24   431    12    28 15779     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: la\n",
            "word: noia\n",
            "word: della\n",
            "word: domenica\n",
            "word: non\n",
            "word: ha\n",
            "word: eguali\n",
            "sentence\n",
            "[ 6113    48   928 15780    33 15781    39    22   113    41     2  1451\n",
            "    30    16  2883     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: colvieux\n",
            "word: ho\n",
            "word: amato\n",
            "word: carver\n",
            "word: sono\n",
            "word: stupefatta\n",
            "word: come\n",
            "word: si\n",
            "word: può\n",
            "word: fare\n",
            "word: il\n",
            "word: confronto\n",
            "word: con\n",
            "word: un\n",
            "word: cantante\n",
            "sentence\n",
            "[15782   516    39   117    21   481 15783    11   208   548     9   199\n",
            "    58  3939    34     9  1119     9  2208   183     0     0     0     0\n",
            "     0]\n",
            "word: acciodarren\n",
            "word: oddio\n",
            "word: come\n",
            "word: mai\n",
            "word: ma\n",
            "word: quindi\n",
            "word: torneremmo\n",
            "word: la\n",
            "word: sera\n",
            "word: stessa\n",
            "word: a\n",
            "word: casa\n",
            "word: o\n",
            "word: staremmo\n",
            "word: tutti\n",
            "word: a\n",
            "word: dormire\n",
            "word: a\n",
            "word: firenze\n",
            "word: lol\n",
            "sentence\n",
            "[ 5532 15784   308    11    71   480     7     5     6 15785     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: vstaffelli\n",
            "word: vinile\n",
            "word: tutta\n",
            "word: la\n",
            "word: vita\n",
            "word: p\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ys4mdswl\n",
            "sentence\n",
            "[ 5000 15786 15787 15788    54     7     5     6 15789 15790     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: michel\n",
            "word: platini\n",
            "word: itu\n",
            "word: urusan\n",
            "word: italia\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: hbeuozas\n",
            "word: sepakbolainfo\n",
            "sentence\n",
            "[15791    35 15792  1255  2667    19 15793 15794 15795  6014 15796 15797\n",
            " 15798     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: fettucini\n",
            "word: alla\n",
            "word: amatriciana\n",
            "word: ama\n",
            "word: ristorante\n",
            "word: in\n",
            "word: atlantic\n",
            "word: highlands\n",
            "word: nj\n",
            "word: call\n",
            "word: 732\n",
            "word: 872\n",
            "word: 4674\n",
            "sentence\n",
            "[   27    13  1291    16   153     3   196     7     5     6 15799   989\n",
            " 15800    48   327  2936 15801 15802     0     0     0     0     0     0\n",
            "     0]\n",
            "word: mi\n",
            "word: è\n",
            "word: piaciuto\n",
            "word: un\n",
            "word: video\n",
            "word: di\n",
            "word: youtube\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: y2bzvtgt\n",
            "word: paolo\n",
            "word: meneguzzi\n",
            "word: ho\n",
            "word: bisogno\n",
            "word: d'amore\n",
            "word: videoclip\n",
            "word: ©nihi\n",
            "sentence\n",
            "[ 1513 15803  1985    45   270     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: louis\n",
            "word: tommoo\n",
            "word: sisi\n",
            "word: tutto\n",
            "word: ok\n",
            "sentence\n",
            "[15804    46    70     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: charlieagron\n",
            "word: grazie\n",
            "word: 3\n",
            "sentence\n",
            "[  225   431     9    34    70 15805   677  3993     9 15806    14   190\n",
            "    65  3722   315  2308   108    16 15807     7     5     6 15808     0\n",
            "     0]\n",
            "word: buona\n",
            "word: domenica\n",
            "word: a\n",
            "word: tutti\n",
            "word: 3\n",
            "word: 605\n",
            "word: fan\n",
            "word: aiutatemi\n",
            "word: a\n",
            "word: vincereeee\n",
            "word: per\n",
            "word: adesso\n",
            "word: solo\n",
            "word: 140\n",
            "word: voti\n",
            "word: please\n",
            "word: prima\n",
            "word: un\n",
            "word: click\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 9bg4vnwe\n",
            "sentence\n",
            "[ 6114 15809    46   120     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: chia\n",
            "word: lovesharry\n",
            "word: grazie\n",
            "word: d\n",
            "sentence\n",
            "[    8    82  1302    25    16 15810    13    38  3994     3    68  2921\n",
            "  2921     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: e\n",
            "word: poi\n",
            "word: boh\n",
            "word: anche\n",
            "word: un\n",
            "word: koala\n",
            "word: è\n",
            "word: più\n",
            "word: fortunato\n",
            "word: di\n",
            "word: me\n",
            "word: ç\n",
            "word: ç\n",
            "sentence\n",
            "[15811  1175    27 15812    14    49   272    21    82    33   359   151\n",
            "  5550     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: gafertekoias\n",
            "word: ahahaha\n",
            "word: mi\n",
            "word: ombottivo\n",
            "word: per\n",
            "word: bene\n",
            "word: xd\n",
            "word: ma\n",
            "word: poi\n",
            "word: sono\n",
            "word: stata\n",
            "word: male\n",
            "word: loool\n",
            "sentence\n",
            "[  48  301  220    2 1368 1810 2854  559 6074   35 2167    3   17    9\n",
            " 1076  104 3995    0    0    0    0    0    0    0    0]\n",
            "word: ho\n",
            "word: appena\n",
            "word: visto\n",
            "word: il\n",
            "word: tg3\n",
            "word: regione\n",
            "word: sicilia\n",
            "word: nessun\n",
            "word: riferimento\n",
            "word: alla\n",
            "word: presenza\n",
            "word: di\n",
            "word: grillo\n",
            "word: a\n",
            "word: palermo\n",
            "word: siamo\n",
            "word: invisibili\n",
            "sentence\n",
            "[ 2861    24 15813  4726     2  1137     7     5     6 15814     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: l'uso\n",
            "word: della\n",
            "word: cocaina\n",
            "word: invecchia\n",
            "word: il\n",
            "word: cervello\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 7ryw8hsj\n",
            "sentence\n",
            "[  76  174 3739   58    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: quanto\n",
            "word: tempo\n",
            "word: galera\n",
            "word: o\n",
            "sentence\n",
            "[    7     5     6 15815  6115 15816    24  1387 15817   120  2395  6116\n",
            "    54  4410  6115 15818  1387 15819   120  2395  6116    54     0     0\n",
            "     0]\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 3vaby7kx\n",
            "word: memorie\n",
            "word: descrittive\n",
            "word: della\n",
            "word: carta\n",
            "word: geologica\n",
            "word: d\n",
            "word: amp\n",
            "word: 039\n",
            "word: italia\n",
            "word: 51\n",
            "word: memorie\n",
            "word: descritt\n",
            "word: carta\n",
            "word: geol\n",
            "word: d\n",
            "word: amp\n",
            "word: 039\n",
            "word: italia\n",
            "sentence\n",
            "[15820  2273   119     2  5628  2888     3 15821   123    20   303    38\n",
            " 15822   958  6117   313  6117 15823  2273   119     2     7     5     6\n",
            " 15824]\n",
            "word: compie\n",
            "word: 80\n",
            "word: anni\n",
            "word: il\n",
            "word: moto\n",
            "word: club\n",
            "word: di\n",
            "word: smcv\n",
            "word: tra\n",
            "word: i\n",
            "word: 20\n",
            "word: più\n",
            "word: antichi\n",
            "word: d'italia\n",
            "word: caserta\n",
            "word: news\n",
            "word: caserta\n",
            "word: newscompie\n",
            "word: 80\n",
            "word: anni\n",
            "word: il\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: c1cw5mbg\n",
            "sentence\n",
            "[ 6118 15825    51  2495     8    98    10  1767    28    19 15826     5\n",
            "     6 15827     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: classi\n",
            "word: bloccate\n",
            "word: su\n",
            "word: italo\n",
            "word: e\n",
            "word: l'italia\n",
            "word: che\n",
            "word: montezemolo\n",
            "word: ha\n",
            "word: in\n",
            "word: mentehttp\n",
            "word: t\n",
            "word: co\n",
            "word: vdy9riur\n",
            "sentence\n",
            "[  149    25    23   267     3 15828    10   408     9 15829   242     7\n",
            "     5     6 15830     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ecco\n",
            "word: anche\n",
            "word: le\n",
            "word: foto\n",
            "word: di\n",
            "word: kristen\n",
            "word: che\n",
            "word: arriva\n",
            "word: a\n",
            "word: vancouverqui\n",
            "word: tutte\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: tkzojr34\n",
            "sentence\n",
            "[15831   936    10    12  2691  1122    19  2854    18   170  1710     8\n",
            "    42    10   515    25  1315     2 15832     3 15833 15834   888     0\n",
            "     0]\n",
            "word: mrsimonoh\n",
            "word: peccato\n",
            "word: che\n",
            "word: non\n",
            "word: c'erano\n",
            "word: date\n",
            "word: in\n",
            "word: sicilia\n",
            "word: del\n",
            "word: suo\n",
            "word: tour\n",
            "word: e\n",
            "word: io\n",
            "word: che\n",
            "word: avevo\n",
            "word: anche\n",
            "word: imparato\n",
            "word: il\n",
            "word: balletto\n",
            "word: di\n",
            "word: anal\n",
            "word: beat\n",
            "word: delusione\n",
            "sentence\n",
            "[    2   224    18   106  3833  1522 15835  1882    51  1910  6119  2154\n",
            "    64  2476    19   422 15836    20     7     5     6 15837     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: mondo\n",
            "word: del\n",
            "word: lavoro\n",
            "word: •\n",
            "word: re\n",
            "word: rimborso\n",
            "word: irpef\n",
            "word: su\n",
            "word: cassa\n",
            "word: marittima\n",
            "word: dovevo\n",
            "word: ancora\n",
            "word: nascere\n",
            "word: in\n",
            "word: quelle\n",
            "word: datestatistiche\n",
            "word: i\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: gkpuwxkd\n",
            "sentence\n",
            "[15838   370   270    25     9    68  1536     9   454     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: marikina722\n",
            "word: ah\n",
            "word: ok\n",
            "word: anche\n",
            "word: a\n",
            "word: me\n",
            "word: succede\n",
            "word: a\n",
            "word: volte\n",
            "sentence\n",
            "[15839    46 15840    40 15841    14  6036    18  1182    18 15842     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: shivaqueen\n",
            "word: grazie\n",
            "word: shiva\n",
            "word: ci\n",
            "word: risentiamo\n",
            "word: per\n",
            "word: l'edizione\n",
            "word: del\n",
            "word: pomeriggio\n",
            "word: del\n",
            "word: meteojacopo\n",
            "sentence\n",
            "[ 1579 15843    18 15844    30     2    93   176 15845 15846     7     5\n",
            "     6 15847   180    70     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: dia\n",
            "word: mundial\n",
            "word: del\n",
            "word: jazz\n",
            "word: con\n",
            "word: il\n",
            "word: mio\n",
            "word: amore\n",
            "word: chet\n",
            "word: baker\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: rug0lwit\n",
            "word: lt\n",
            "word: 3\n",
            "sentence\n",
            "[15848    22    21    25    31   318    29    56    19  1349   169    38\n",
            "  6120    44  2723   162     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: martinadreams\n",
            "word: si\n",
            "word: ma\n",
            "word: anche\n",
            "word: se\n",
            "word: fai\n",
            "word: una\n",
            "word: cosa\n",
            "word: in\n",
            "word: piccolo\n",
            "word: hai\n",
            "word: più\n",
            "word: possibilitá\n",
            "word: ti\n",
            "word: venga\n",
            "word: meglio\n",
            "sentence\n",
            "[15849   894    10    40    22   113 15850    25   284   363    10   563\n",
            " 15851     9 15852 15853     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: 88beppe\n",
            "word: direi\n",
            "word: che\n",
            "word: ci\n",
            "word: si\n",
            "word: può\n",
            "word: beccare\n",
            "word: anche\n",
            "word: qui\n",
            "word: dato\n",
            "word: che\n",
            "word: ormai\n",
            "word: abiti\n",
            "word: a\n",
            "word: muggiò\n",
            "word: muahhaaha\n",
            "sentence\n",
            "[15854  6121 15855    59    59   159    25   101   269     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: mrs\n",
            "word: horan\n",
            "word: keviiin\n",
            "word: no\n",
            "word: no\n",
            "word: dai\n",
            "word: anche\n",
            "word: tu\n",
            "word: finalmente\n",
            "sentence\n",
            "[15856 15857    46    27  2925  1041   101     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xchiaramalik1d\n",
            "word: ohh\n",
            "word: grazie\n",
            "word: mi\n",
            "word: chiamo\n",
            "word: anna\n",
            "word: tu\n",
            "sentence\n",
            "[1444   44  450   10   77 1903   56  318   12   40  358  362   25   31\n",
            "   40 3269  151   37  381    0    0    0    0    0    0]\n",
            "word: 26\n",
            "word: ti\n",
            "word: dicono\n",
            "word: che\n",
            "word: sei\n",
            "word: brutta\n",
            "word: cosa\n",
            "word: fai\n",
            "word: non\n",
            "word: ci\n",
            "word: faccio\n",
            "word: caso\n",
            "word: anche\n",
            "word: se\n",
            "word: ci\n",
            "word: rimango\n",
            "word: male\n",
            "word: lo\n",
            "word: stesso\n",
            "sentence\n",
            "[15858    25    42    23   145  2874     3  6122   151    10   850    40\n",
            "  1583   595   183     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: theyareswag\n",
            "word: anche\n",
            "word: io\n",
            "word: le\n",
            "word: sto\n",
            "word: cercando\n",
            "word: di\n",
            "word: convincere\n",
            "word: male\n",
            "word: che\n",
            "word: vada\n",
            "word: ci\n",
            "word: andiamo\n",
            "word: insieme\n",
            "word: lol\n",
            "sentence\n",
            "[   48   301  2885 15859 15860    51  2886   159  2345    35    95  2887\n",
            "     7     5     6 15861     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ho\n",
            "word: appena\n",
            "word: acquistato\n",
            "word: cottage\n",
            "word: table\n",
            "word: su\n",
            "word: stardoll\n",
            "word: dai\n",
            "word: un'occhiata\n",
            "word: alla\n",
            "word: mia\n",
            "word: suite\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 8p7eweiq\n",
            "sentence\n",
            "[15862    45  1121    94    25 15863     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xcesciambella\n",
            "word: tutto\n",
            "word: benissimo\n",
            "word: te\n",
            "word: anche\n",
            "word: tu♥\n",
            "sentence\n",
            "[   20  6123    22    22   967    31    22   169    16   131   372    46\n",
            "   679     2   248  1820   673    13 15864    59    13    64  1043    32\n",
            " 15865]\n",
            "word: i\n",
            "word: phone\n",
            "word: si\n",
            "word: si\n",
            "word: 22\n",
            "word: se\n",
            "word: si\n",
            "word: hai\n",
            "word: un\n",
            "word: grande\n",
            "word: culo\n",
            "word: grazie\n",
            "word: 23\n",
            "word: il\n",
            "word: tuo\n",
            "word: account\n",
            "word: facebook\n",
            "word: è\n",
            "word: ammuffito\n",
            "word: no\n",
            "word: è\n",
            "word: ancora\n",
            "word: buono\n",
            "word: da\n",
            "word: pappare\n",
            "sentence\n",
            "[15866    21    11   143   184   132   154  6045    58  2353    31    59\n",
            "   192    13  2469     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xinspirahul\n",
            "word: ma\n",
            "word: la\n",
            "word: gente\n",
            "word: deve\n",
            "word: x\n",
            "word: forza\n",
            "word: offendere\n",
            "word: o\n",
            "word: insultare\n",
            "word: se\n",
            "word: no\n",
            "word: nn\n",
            "word: è\n",
            "word: contenta\n",
            "sentence\n",
            "[ 1274 15867  1986     8    25 15868   894   348   348     8  2292    10\n",
            "    42  2010    11 15869    24   570   120     0     0     0     0     0\n",
            "     0]\n",
            "word: sara\n",
            "word: 1dxx\n",
            "word: hahah\n",
            "word: e\n",
            "word: anche\n",
            "word: notevoli\n",
            "word: direi\n",
            "word: u\n",
            "word: u\n",
            "word: e\n",
            "word: diciamo\n",
            "word: che\n",
            "word: io\n",
            "word: sarei\n",
            "word: la\n",
            "word: secchiona\n",
            "word: della\n",
            "word: classe\n",
            "word: d\n",
            "sentence\n",
            "[ 5938  6124    44   658  2986    10   123     2   394     8     2   461\n",
            " 15870    77     9   198     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: justelisabetta\n",
            "word: eli\n",
            "word: ti\n",
            "word: prego\n",
            "word: dimmi\n",
            "word: che\n",
            "word: tra\n",
            "word: il\n",
            "word: 12\n",
            "word: e\n",
            "word: il\n",
            "word: 18\n",
            "word: giugno\n",
            "word: sei\n",
            "word: a\n",
            "word: milano\n",
            "sentence\n",
            "[557  46   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: intanto\n",
            "word: grazie\n",
            "sentence\n",
            "[  132 15871    21    68   901    10   169    43  5877   169   606    20\n",
            " 15872     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: x\n",
            "word: inlovewithian\n",
            "word: ma\n",
            "word: me\n",
            "word: dici\n",
            "word: che\n",
            "word: hai\n",
            "word: fatto\n",
            "word: xk\n",
            "word: hai\n",
            "word: messo\n",
            "word: i\n",
            "word: puntini\n",
            "sentence\n",
            "[  735    38 15873    24    95    71     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: l'ora\n",
            "word: più\n",
            "word: interminabile\n",
            "word: della\n",
            "word: mia\n",
            "word: vita\n",
            "sentence\n",
            "[15874     8   522   826    53  1376    10    92  2653   132     2   118\n",
            "   241    92   668  4518   132  3272   867    98     8    25   112     0\n",
            "     0]\n",
            "word: soter78\n",
            "word: e\n",
            "word: magari\n",
            "word: son\n",
            "word: gli\n",
            "word: stessi\n",
            "word: che\n",
            "word: hanno\n",
            "word: votato\n",
            "word: x\n",
            "word: il\n",
            "word: pdl\n",
            "word: dove\n",
            "word: hanno\n",
            "word: molti\n",
            "word: indagati\n",
            "word: x\n",
            "word: mafia\n",
            "word: purtroppo\n",
            "word: l'italia\n",
            "word: e\n",
            "word: anche\n",
            "word: questa\n",
            "sentence\n",
            "[    7     5     6 15875 15876  1308    42   178  4960     9    34     8\n",
            "   402    39  1026 15877 15878     8 15879     9     0     0     0     0\n",
            "     0]\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: xc3xxrwy\n",
            "word: dannata\n",
            "word: onda\n",
            "word: io\n",
            "word: vi\n",
            "word: stupro\n",
            "word: a\n",
            "word: tutti\n",
            "word: e\n",
            "word: tre\n",
            "word: come\n",
            "word: state\n",
            "word: kyuhyun\n",
            "word: eunhyuk\n",
            "word: e\n",
            "word: leeteuk\n",
            "word: a\n",
            "sentence\n",
            "[15880 15881    45  1730    30    11   205 15882    26 15883   320   265\n",
            "  1692    58    58     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: sheispale\n",
            "word: camminava\n",
            "word: tutto\n",
            "word: tranquillo\n",
            "word: con\n",
            "word: la\n",
            "word: sua\n",
            "word: tracolla\n",
            "word: al\n",
            "word: boschetto\n",
            "word: credo\n",
            "word: fosse\n",
            "word: lì\n",
            "word: o\n",
            "word: o\n",
            "sentence\n",
            "[ 182 6125  101   44   77 3784  443   42   24  229 2199  104 3834    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: ciao\n",
            "word: tata\n",
            "word: tu\n",
            "word: ti\n",
            "word: sei\n",
            "word: innamorata\n",
            "word: dell'italia\n",
            "word: io\n",
            "word: della\n",
            "word: tua\n",
            "word: spagna\n",
            "word: siamo\n",
            "word: pari\n",
            "sentence\n",
            "[   81  4537  4908    11  5295    31    63   335  2396 15884    23  5763\n",
            "   242     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: perché\n",
            "word: desidero\n",
            "word: stampare\n",
            "word: la\n",
            "word: ricevuta\n",
            "word: se\n",
            "word: dopo\n",
            "word: 8\n",
            "word: secondi\n",
            "word: netti\n",
            "word: le\n",
            "word: perdo\n",
            "word: tutte\n",
            "sentence\n",
            "[15885 15886 15887    69  1694   779    12    28    64  1992    68     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: sonobatman\n",
            "word: diffidente\n",
            "word: cattivissimo\n",
            "word: e'\n",
            "word: cosi'\n",
            "word: perche'\n",
            "word: non\n",
            "word: ha\n",
            "word: ancora\n",
            "word: conosciuto\n",
            "word: me\n",
            "sentence\n",
            "[15888 15889    64    19  2319     8   206 15890 15891 15892    12    22\n",
            "    55   399    14   157     7     5     6 15893     0     0     0     0\n",
            "     0]\n",
            "word: gragrazer\n",
            "word: attivisti\n",
            "word: ancora\n",
            "word: in\n",
            "word: carcere\n",
            "word: e\n",
            "word: altri\n",
            "word: 2500\n",
            "word: beagle\n",
            "word: prigionieri\n",
            "word: non\n",
            "word: si\n",
            "word: fa\n",
            "word: nulla\n",
            "word: per\n",
            "word: loro\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 9gbvl9wd\n",
            "sentence\n",
            "[15894 15895    21   678   156   169    43     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: martintudor18\n",
            "word: erikasaavedra90\n",
            "word: ma\n",
            "word: ke\n",
            "word: fine\n",
            "word: hai\n",
            "word: fatto\n",
            "sentence\n",
            "[ 2745 15896    94    37  6126     9  3928    35 15897   583     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: el\n",
            "word: flaqkoo\n",
            "word: te\n",
            "word: lo\n",
            "word: voy\n",
            "word: a\n",
            "word: dar\n",
            "word: alla\n",
            "word: mimo\n",
            "word: ♥\n",
            "sentence\n",
            "[15898     3  2623 15899    23 15900     9    75     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: antonaccibiagio\n",
            "word: di\n",
            "word: fronte\n",
            "word: all'ippodromo\n",
            "word: le\n",
            "word: cappanelle\n",
            "word: a\n",
            "word: roma\n",
            "sentence\n",
            "[15901     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: daiiiiiii\n",
            "sentence\n",
            "[15902 15903    40   122    25    29   709 15904  1440  1602     3    68\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ciccicrokki\n",
            "word: finché\n",
            "word: ci\n",
            "word: sarà\n",
            "word: anche\n",
            "word: una\n",
            "word: sola\n",
            "word: stellina\n",
            "word: sarò\n",
            "word: soddisfatto\n",
            "word: di\n",
            "word: me\n",
            "sentence\n",
            "[15905    22    22     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: linaospino24\n",
            "word: si\n",
            "word: si\n",
            "sentence\n",
            "[6127   27  419   39   29 6065    9  454  246   22 3413    3   68    9\n",
            "  454   33    3  173    8    9  454   12 2248    9  399]\n",
            "word: mondoditumblr\n",
            "word: mi\n",
            "word: sento\n",
            "word: come\n",
            "word: una\n",
            "word: virgola\n",
            "word: a\n",
            "word: volte\n",
            "word: qualcuno\n",
            "word: si\n",
            "word: dimentica\n",
            "word: di\n",
            "word: me\n",
            "word: a\n",
            "word: volte\n",
            "word: sono\n",
            "word: di\n",
            "word: troppo\n",
            "word: e\n",
            "word: a\n",
            "word: volte\n",
            "word: non\n",
            "word: servo\n",
            "word: a\n",
            "word: nulla\n",
            "sentence\n",
            "[15906  2741    40    33 15907  3435  1654 15908    21    27   169   269\n",
            "  1930   121 15909  3781     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: valeriopino\n",
            "word: osanna\n",
            "word: ci\n",
            "word: sono\n",
            "word: voluti\n",
            "word: 35\n",
            "word: 000\n",
            "word: messicani\n",
            "word: ma\n",
            "word: mi\n",
            "word: hai\n",
            "word: finalmente\n",
            "word: risposto\n",
            "word: senza\n",
            "word: tag\n",
            "word: hahahahaha\n",
            "sentence\n",
            "[15910  2987    11   406    10    28     2  2983   245    94  1074   281\n",
            " 15911     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: 82\n",
            "word: menziona\n",
            "word: la\n",
            "word: persona\n",
            "word: che\n",
            "word: ha\n",
            "word: il\n",
            "word: nick\n",
            "word: secondo\n",
            "word: te\n",
            "word: piu\n",
            "word: bello\n",
            "word: demisfreedom\n",
            "sentence\n",
            "[15912    60  1398  5812  6128  6129 15913 15914    30   126    11   674\n",
            "     8    23 15915    19  1303    30    11 15916     7     5     6 15917\n",
            "     0]\n",
            "word: raid\n",
            "word: nel\n",
            "word: fondo\n",
            "word: rustico\n",
            "word: ciro\n",
            "word: corona\n",
            "word: “si\n",
            "word: mobilitino\n",
            "word: con\n",
            "word: noi\n",
            "word: la\n",
            "word: città\n",
            "word: e\n",
            "word: le\n",
            "word: istituzioni”\n",
            "word: in\n",
            "word: viaggio\n",
            "word: con\n",
            "word: la\n",
            "word: mehari\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: hizt2jlgbt\n",
            "sentence\n",
            "[  648     9    11  1071  3996    11   972 15918    19  1609     9   771\n",
            " 15919   319    13  3401  1304    30    11     7     5     6 15920     0\n",
            "     0]\n",
            "word: serie\n",
            "word: a\n",
            "word: la\n",
            "word: fiorentina\n",
            "word: ospita\n",
            "word: la\n",
            "word: juventus\n",
            "word: l’inter\n",
            "word: in\n",
            "word: scena\n",
            "word: a\n",
            "word: torino\n",
            "word: l’ottava\n",
            "word: giornata\n",
            "word: è\n",
            "word: iniziata\n",
            "word: venerdì\n",
            "word: con\n",
            "word: la\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: j4lodwv5th\n",
            "sentence\n",
            "[   36 15921  3997     7     5     6 15922     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: barbieharp\n",
            "word: capisci\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: creh7el494\n",
            "sentence\n",
            "[15923 15924   130     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: cimarapr\n",
            "word: leopoldo\n",
            "word: presidente\n",
            "sentence\n",
            "[15925  3026    19 15926    32  6024     9   766  1110 15927 15928 15929\n",
            "  3998 15930 15931  2828     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ss16\n",
            "word: traffico\n",
            "word: in\n",
            "word: congestione\n",
            "word: da\n",
            "word: pesaro\n",
            "word: a\n",
            "word: s\n",
            "word: maria\n",
            "word: innesto\n",
            "word: ss423\n",
            "word: urbinate\n",
            "word: velocità\n",
            "word: rilevata\n",
            "word: 10km\n",
            "word: h\n",
            "sentence\n",
            "[ 1615  3940 15932 15933 15934 15935   233  5168 15936 15937    75     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: info\n",
            "word: atac\n",
            "word: metropolitana\n",
            "word: aperte\n",
            "word: stazioni\n",
            "word: barberini\n",
            "word: repubblica\n",
            "word: castro\n",
            "word: pretorio\n",
            "word: colosseo\n",
            "word: roma\n",
            "sentence\n",
            "[15938 15939     7     5     6 15940     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: morango\n",
            "word: ingrata\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: aw6snxiph2\n",
            "sentence\n",
            "[   36 15941 15942   203     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: benxfrank\n",
            "word: baeless\n",
            "word: bella\n",
            "sentence\n",
            "[    3   178    59     7     5     6 15943     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: di\n",
            "word: vi\n",
            "word: no\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: zwgxlzwn1y\n",
            "sentence\n",
            "[ 299 1319 1319 1319  299    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: '\n",
            "word: ❤\n",
            "word: ❤\n",
            "word: ❤\n",
            "word: '\n",
            "sentence\n",
            "[   36  3654  6130 15944   634 15945    18  1894    14  6131   159    85\n",
            " 15946     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: guidomeda\n",
            "word: motogp\n",
            "word: ahia\n",
            "word: seconda\n",
            "word: scivolata\n",
            "word: del\n",
            "word: weekend\n",
            "word: per\n",
            "word: marquez\n",
            "word: dai\n",
            "word: sta\n",
            "word: calmo\n",
            "sentence\n",
            "[   13    16  2348     7     5     6 15947     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: è\n",
            "word: un\n",
            "word: segreto\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: alwgv8nnng\n",
            "sentence\n",
            "[  238  3968    35 15948    21   245    68    12   160    16  3999     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: primo\n",
            "word: passaggio\n",
            "word: alla\n",
            "word: strabrollo\n",
            "word: ma\n",
            "word: secondo\n",
            "word: me\n",
            "word: non\n",
            "word: era\n",
            "word: un\n",
            "word: iscritto\n",
            "sentence\n",
            "[15949 15950    12   803   979     9 15951    23  3266   604    18   124\n",
            "    20   262  1206   103   158   596   346     0     0     0     0     0\n",
            "     0]\n",
            "word: francofontana43\n",
            "word: ahimè\n",
            "word: non\n",
            "word: possiamo\n",
            "word: continuare\n",
            "word: a\n",
            "word: sacrificare\n",
            "word: le\n",
            "word: menti\n",
            "word: migliori\n",
            "word: del\n",
            "word: paese\n",
            "word: i\n",
            "word: giovani\n",
            "word: appello\n",
            "word: ai\n",
            "word: politici\n",
            "word: fate\n",
            "word: qualcosa\n",
            "sentence\n",
            "[   73     2 15952    13  2988  2395  2988     9   174   742  2988   225\n",
            "   431 15953   182     7     5     6 15954     0     0     0     0     0\n",
            "     0]\n",
            "word: oggi\n",
            "word: il\n",
            "word: motto\n",
            "word: è\n",
            "word: relax\n",
            "word: amp\n",
            "word: relax\n",
            "word: a\n",
            "word: tempo\n",
            "word: perso\n",
            "word: relax\n",
            "word: buona\n",
            "word: domenica\n",
            "word: twitteri\n",
            "word: ciao\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 32vhorwvkx\n",
            "sentence\n",
            "[ 1149   665    34     9 15955    82    80 15956    10  1670     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: qua\n",
            "word: stiamo\n",
            "word: tutti\n",
            "word: a\n",
            "word: scannarci\n",
            "word: poi\n",
            "word: c'è\n",
            "word: marx\n",
            "word: che\n",
            "word: ride\n",
            "sentence\n",
            "[  36 2397  432  305   19  231 1064   11 1153    3   16  462    8   44\n",
            " 6132  519    3   12  283  334  168    0    0    0    0]\n",
            "word: rt\n",
            "word: tweetcomici\n",
            "word: quel\n",
            "word: momento\n",
            "word: in\n",
            "word: cui\n",
            "word: leggi\n",
            "word: la\n",
            "word: pagina\n",
            "word: di\n",
            "word: un\n",
            "word: libro\n",
            "word: e\n",
            "word: ti\n",
            "word: rendi\n",
            "word: conto\n",
            "word: di\n",
            "word: non\n",
            "word: aver\n",
            "word: capito\n",
            "word: niente\n",
            "sentence\n",
            "[   36 15957   770    12 15958    55   416     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: awkiall\n",
            "word: l'amore\n",
            "word: non\n",
            "word: ricambiato\n",
            "word: fa\n",
            "word: schifo\n",
            "sentence\n",
            "[ 5281    11 15959    27    28 15960  1175    58    58     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: betty\n",
            "word: la\n",
            "word: fea\n",
            "word: mi\n",
            "word: ha\n",
            "word: traumatizzata\n",
            "word: ahahaha\n",
            "word: o\n",
            "word: o\n",
            "sentence\n",
            "[ 2077     3   106    51  6133  1627 15961 15962 15963    10    40    33\n",
            "  2077     3   106    51  6133  1627     7     5     6 15964     0     0\n",
            "     0]\n",
            "word: offerte\n",
            "word: di\n",
            "word: lavoro\n",
            "word: su\n",
            "word: sofia\n",
            "word: hotel\n",
            "word: dubai\n",
            "word: desideriamo\n",
            "word: informarvi\n",
            "word: che\n",
            "word: ci\n",
            "word: sono\n",
            "word: offerte\n",
            "word: di\n",
            "word: lavoro\n",
            "word: su\n",
            "word: sofia\n",
            "word: hotel\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: bur3kv2ube\n",
            "sentence\n",
            "[15965    46  2782    25   132    94     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: alebenetti58\n",
            "word: grazie\n",
            "word: alessandro\n",
            "word: anche\n",
            "word: x\n",
            "word: te\n",
            "sentence\n",
            "[   36 15966    95   420  6134   173     9  1196   207 15967    25     2\n",
            " 15968     3 15969    21  1163     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: alonegjrl\n",
            "word: mia\n",
            "word: mamma\n",
            "word: rompe\n",
            "word: troppo\n",
            "word: a\n",
            "word: momenti\n",
            "word: devo\n",
            "word: chiederle\n",
            "word: anche\n",
            "word: il\n",
            "word: permesso\n",
            "word: di\n",
            "word: respirare\n",
            "word: ma\n",
            "word: vaffanculo\n",
            "sentence\n",
            "[  212   830 15970  6135    40    28 15971     8    55   241  2376   780\n",
            "  3604    40   191  1930   642    10  3652     0     0     0     0     0\n",
            "     0]\n",
            "word: invece\n",
            "word: stavo\n",
            "word: morendo\n",
            "word: un'altro\n",
            "word: ci\n",
            "word: ha\n",
            "word: fermate\n",
            "word: e\n",
            "word: fa\n",
            "word: dove\n",
            "word: andate\n",
            "word: belle\n",
            "word: affanculo\n",
            "word: ci\n",
            "word: abbiamo\n",
            "word: risposto\n",
            "word: dio\n",
            "word: che\n",
            "word: nervi\n",
            "sentence\n",
            "[   11 15972    13   225    65    91 15973  3423     8    11  5627     9\n",
            " 15974     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: la\n",
            "word: yamaha\n",
            "word: è\n",
            "word: buona\n",
            "word: solo\n",
            "word: ad\n",
            "word: alzar\n",
            "word: polemiche\n",
            "word: e\n",
            "word: la\n",
            "word: honda\n",
            "word: a\n",
            "word: crearne\n",
            "sentence\n",
            "[  977    11  1827  6136   204    19 15975    14 15976    20  1027    10\n",
            "    55     7     5     6 15977    47   977 15978 15979     0     0     0\n",
            "     0]\n",
            "word: linkiesta\n",
            "word: la\n",
            "word: cina\n",
            "word: compra\n",
            "word: tv\n",
            "word: in\n",
            "word: africa\n",
            "word: per\n",
            "word: coprire\n",
            "word: i\n",
            "word: danni\n",
            "word: che\n",
            "word: fa\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: snvukmdgwq\n",
            "word: via\n",
            "word: linkiesta\n",
            "word: softpower\n",
            "word: miricordaqualcosa\n",
            "sentence\n",
            "[15980   257  1309     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: clandestina0204\n",
            "word: buongiorno\n",
            "word: cara\n",
            "sentence\n",
            "[    8    82    48  6137   528    53 15981    27 15982     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: e\n",
            "word: poi\n",
            "word: ho\n",
            "word: dormito\n",
            "word: mentre\n",
            "word: gli\n",
            "word: incubi\n",
            "word: mi\n",
            "word: tormentavano\n",
            "sentence\n",
            "[15983 15984  6138 15985    12    77 15986    58    77    19  4550    11\n",
            " 15987    13 15988    21   288   111    12 15989     0     0     0     0\n",
            "     0]\n",
            "word: giancarlocantel\n",
            "word: gianlucabergese\n",
            "word: maboniver\n",
            "word: gcarlo\n",
            "word: non\n",
            "word: sei\n",
            "word: informato\n",
            "word: o\n",
            "word: sei\n",
            "word: in\n",
            "word: malafede\n",
            "word: la\n",
            "word: frode\n",
            "word: è\n",
            "word: accertata\n",
            "word: ma\n",
            "word: b\n",
            "word: dice\n",
            "word: non\n",
            "word: sapevo'\n",
            "sentence\n",
            "[15990   175 15991     2   939     8    11  1359    50 15992     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: marilumanzini\n",
            "word: li\n",
            "word: accomuna\n",
            "word: il\n",
            "word: numero\n",
            "word: e\n",
            "word: la\n",
            "word: qualità\n",
            "word: dei\n",
            "word: neuroni\n",
            "sentence\n",
            "[   36 15993 15994     8 15995    51 15996     8    11  1144 15997    32\n",
            " 15998 15999  1983 16000     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: massarenti24\n",
            "word: onfray\n",
            "word: e\n",
            "word: escobar\n",
            "word: su\n",
            "word: camus\n",
            "word: e\n",
            "word: la\n",
            "word: lezione\n",
            "word: appresa\n",
            "word: da\n",
            "word: nietzsche\n",
            "word: ponteallegrazie\n",
            "word: copertina\n",
            "word: 24domenica\n",
            "sentence\n",
            "[16001    22    81    20   339    12    92    11  1117    22    19  1370\n",
            "   222  2371    86   947    81    42    37 16002   228   183     0     0\n",
            "     0]\n",
            "word: englishipster\n",
            "word: si\n",
            "word: perché\n",
            "word: i\n",
            "word: miei\n",
            "word: non\n",
            "word: hanno\n",
            "word: la\n",
            "word: macchina\n",
            "word: si\n",
            "word: in\n",
            "word: effetti\n",
            "word: però\n",
            "word: rimane\n",
            "word: sempre\n",
            "word: bellissimo\n",
            "word: perché\n",
            "word: io\n",
            "word: lo\n",
            "word: bacerei\n",
            "word: comunque\n",
            "word: lol\n",
            "sentence\n",
            "[16003  2506  4000     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: geografi\n",
            "word: nani\n",
            "word: hahahah\n",
            "sentence\n",
            "[ 2969 16004 16005     9   156   552     2 16006     9   156   552 16007\n",
            "    20  3018 16008 16009     7     5     6 16010     0     0     0     0\n",
            "     0]\n",
            "word: catanzaro\n",
            "word: operazione\n",
            "word: perseo\n",
            "word: a\n",
            "word: fine\n",
            "word: mese\n",
            "word: il\n",
            "word: verdetto\n",
            "word: a\n",
            "word: fine\n",
            "word: mese\n",
            "word: scadranno\n",
            "word: i\n",
            "word: termini\n",
            "word: processuali\n",
            "word: relativ\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: nqetbxw4aa\n",
            "sentence\n",
            "[  257     2    93  2812    73    13    14    11    95   420   779    13\n",
            "     2   170  1077    44   172 16012    77    11    95    71     7     5\n",
            "  2989]\n",
            "word: buongiorno\n",
            "word: il\n",
            "word: mio\n",
            "word: augurio\n",
            "word: oggi\n",
            "word: è\n",
            "word: per\n",
            "word: la\n",
            "word: mia\n",
            "word: mamma\n",
            "word: perche'\n",
            "word: è\n",
            "word: il\n",
            "word: suo\n",
            "word: compleanno\n",
            "word: ti\n",
            "word: amo\n",
            "word: mamy\n",
            "word: sei\n",
            "word: la\n",
            "word: mia\n",
            "word: vita\n",
            "word: http\n",
            "word: t\n",
            "word: c…\n",
            "sentence\n",
            "[   36 16013  4137 16014   149 16015    18  6139    19  2760  2245 16016\n",
            "    51  1490     5     6 16017  6140     7     5     6 16018     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: ilmanifesto\n",
            "word: et\n",
            "word: voilà\n",
            "word: ecco\n",
            "word: laprima\n",
            "word: del\n",
            "word: manifesto\n",
            "word: in\n",
            "word: edicola\n",
            "word: pre\n",
            "word: abbonatevi\n",
            "word: su\n",
            "word: https\n",
            "word: t\n",
            "word: co\n",
            "word: bglzv38rn4\n",
            "word: 19o\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: nbaey673fp\n",
            "sentence\n",
            "[   36 16019  2698    50  3110   650   214  1717    19  3935    89    10\n",
            "  1681   376     3  2964 16020     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: amorosomylife\n",
            "word: significato\n",
            "word: dei\n",
            "word: vizi\n",
            "word: pt\n",
            "word: 7\n",
            "word: mangiare\n",
            "word: in\n",
            "word: continuazione\n",
            "word: quello\n",
            "word: che\n",
            "word: capita\n",
            "word: senso\n",
            "word: di\n",
            "word: vuoto\n",
            "word: solitudine\n",
            "sentence\n",
            "[   36 16021 16022   529    10   432  4877 16023    12    44  1878 16024\n",
            "    13 16025   203     8   225  2102   143   659  6141  2989     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: yobelieber\n",
            "word: jastindrewbibah\n",
            "word: guarda\n",
            "word: che\n",
            "word: quel\n",
            "word: 'senza\n",
            "word: offesa'\n",
            "word: non\n",
            "word: ti\n",
            "word: rende\n",
            "word: immune\n",
            "word: è\n",
            "word: un'offesa\n",
            "word: bella\n",
            "word: e\n",
            "word: buona\n",
            "word: molta\n",
            "word: gente\n",
            "word: aveva\n",
            "word: selena\n",
            "word: c…\n",
            "sentence\n",
            "[   36 16026  3611     3  2071 16027    79  6139     3    73     7     5\n",
            "     6 16028     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: milanoics\n",
            "word: l'articolo\n",
            "word: di\n",
            "word: roberto\n",
            "word: ciccarelli\n",
            "word: dal\n",
            "word: manifesto\n",
            "word: di\n",
            "word: oggi\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ngzdeshetl\n",
            "sentence\n",
            "[   36 16029  1607    23 16030     7     5     6 16031     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: xharoldshugs\n",
            "word: trova\n",
            "word: le\n",
            "word: differenze\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: xvyns6qzim\n",
            "sentence\n",
            "[1304 1304 1304    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: venerdì\n",
            "word: venerdì\n",
            "word: venerdì\n",
            "sentence\n",
            "[ 6098 16032    43   129     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: smile\n",
            "word: sel1d\n",
            "word: fatto\n",
            "word: c\n",
            "sentence\n",
            "[16033   109    49     3  1387     3  1815   200    96     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: onedshappjness\n",
            "word: va\n",
            "word: bene\n",
            "word: di\n",
            "word: carta\n",
            "word: di\n",
            "word: giornale\n",
            "word: ce\n",
            "word: crisi\n",
            "sentence\n",
            "[   36  6142    12  1417   356    58  1196 16034  1417    65 16035   944\n",
            "    10   235  2568    45     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: zziagenio78\n",
            "word: non\n",
            "word: esistono\n",
            "word: persone\n",
            "word: o\n",
            "word: momenti\n",
            "word: sbagliati\n",
            "word: esistono\n",
            "word: solo\n",
            "word: birre\n",
            "word: buone\n",
            "word: che\n",
            "word: fanno\n",
            "word: superare\n",
            "word: tutto\n",
            "sentence\n",
            "[16036    48    86 16037    51     3    94     8    12 16038     3   900\n",
            "    14   165    58   402   356    10    27   450    10    77    29   406\n",
            "  4773]\n",
            "word: xsheisagroupie\n",
            "word: ho\n",
            "word: sempre\n",
            "word: contato\n",
            "word: su\n",
            "word: di\n",
            "word: te\n",
            "word: e\n",
            "word: non\n",
            "word: smetterò\n",
            "word: di\n",
            "word: farlo\n",
            "word: per\n",
            "word: due\n",
            "word: o\n",
            "word: tre\n",
            "word: persone\n",
            "word: che\n",
            "word: mi\n",
            "word: dicono\n",
            "word: che\n",
            "word: sei\n",
            "word: una\n",
            "word: persona\n",
            "word: falsa\n",
            "sentence\n",
            "[16039  1269     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: dicebx\n",
            "word: salute\n",
            "sentence\n",
            "[  131  2354   521 16040 16041     7     5     6 16042     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: grande\n",
            "word: genio\n",
            "word: capo\n",
            "word: groso\n",
            "word: idolooooooo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 1uomcqmlyp\n",
            "sentence\n",
            "[   36  6143  6144     3   356    51  6145    11 16043    85    51   187\n",
            "     9   139    10   388   953   212     3   260     9   900     7     5\n",
            "   518]\n",
            "word: rt\n",
            "word: sheerjous\n",
            "word: 'tipi\n",
            "word: di\n",
            "word: persone\n",
            "word: su\n",
            "word: twitter'\n",
            "word: la\n",
            "word: 'studiosa'\n",
            "word: sta\n",
            "word: su\n",
            "word: twitter\n",
            "word: a\n",
            "word: dire\n",
            "word: che\n",
            "word: dovrebbe\n",
            "word: studiare\n",
            "word: invece\n",
            "word: di\n",
            "word: andare\n",
            "word: a\n",
            "word: farlo\n",
            "word: http\n",
            "word: t\n",
            "word: …\n",
            "sentence\n",
            "[16044    36   486     8    44   263  2398    32    99     9   240   132\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: buongiorno💋\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: voto\n",
            "word: l'icon\n",
            "word: da\n",
            "word: uno\n",
            "word: a\n",
            "word: 10\n",
            "word: x\n",
            "sentence\n",
            "[ 5827  1847  1060  5632     3  1895   106    51 16045 16046   879     8\n",
            "  2195  3204     7     5     6 16047     0     0     0     0     0     0\n",
            "     0]\n",
            "word: nota\n",
            "word: agenzia\n",
            "word: ricerca\n",
            "word: operatori\n",
            "word: di\n",
            "word: sicurezza\n",
            "word: lavoro\n",
            "word: su\n",
            "word: turnazione\n",
            "word: massima\n",
            "word: serietà\n",
            "word: e\n",
            "word: professionalità\n",
            "word: inviare\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: gjg02sgla8\n",
            "sentence\n",
            "[ 5994  4001   228    33  4330   485   133    13  4658  6146  6147   101\n",
            "    10   244 16048 16049     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: figurati\n",
            "word: ❤️\n",
            "word: comunque\n",
            "word: sono\n",
            "word: all'ultimo\n",
            "word: anno\n",
            "word: ed\n",
            "word: è\n",
            "word: parecchio\n",
            "word: stressante\n",
            "word: 😔\n",
            "word: tu\n",
            "word: che\n",
            "word: scuola\n",
            "word: frequenti\n",
            "word: estblanc\n",
            "sentence\n",
            "[   36 16050  2369    55     2 16051     8 16052   188 16053     8    82\n",
            "   692 16054  6148   152 16055    74     2  6149     3 16056     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: grandericchiuti\n",
            "word: conte\n",
            "word: fa\n",
            "word: il\n",
            "word: possibilista\n",
            "word: e\n",
            "word: pragmatico\n",
            "word: sui\n",
            "word: moduli\n",
            "word: e\n",
            "word: poi\n",
            "word: dobbiamo\n",
            "word: tenerci\n",
            "word: padoin\n",
            "word: sulla\n",
            "word: fascia\n",
            "word: contro\n",
            "word: il\n",
            "word: principio\n",
            "word: di\n",
            "word: re…\n",
            "sentence\n",
            "[16057 16058 16059 16060 16061 16062   225   431     9    34   223     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: capriccio68\n",
            "word: gabryfrangi\n",
            "word: rebeccaabdu\n",
            "word: massste\n",
            "word: 070andrea\n",
            "word: hott70\n",
            "word: buona\n",
            "word: domenica\n",
            "word: a\n",
            "word: tutti\n",
            "word: voi\n",
            "sentence\n",
            "[16063  3807    34    48   767  1480   406     9   231   114 16064     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ehyhoran\n",
            "word: fermi\n",
            "word: tutti\n",
            "word: ho\n",
            "word: trovato\n",
            "word: un'altra\n",
            "word: persona\n",
            "word: a\n",
            "word: cui\n",
            "word: piace\n",
            "word: fallen\n",
            "sentence\n",
            "[ 335   12  275   10   27  114 4002    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: 8\n",
            "word: non\n",
            "word: sa\n",
            "word: che\n",
            "word: mi\n",
            "word: piace\n",
            "word: 10cosesulragazzochemipiace\n",
            "sentence\n",
            "[  257     8   225   431     7     5     6 16065     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: buongiorno\n",
            "word: e\n",
            "word: buona\n",
            "word: domenica\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ilhjoletxp\n",
            "sentence\n",
            "[257 129   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: buongiorno\n",
            "word: c\n",
            "sentence\n",
            "[   93  1373     3    70    28  1869  1054     2   170  1401  6150   299\n",
            "     8    85   142 16066    10  1271    23  1065    12 16067     0     0\n",
            "     0]\n",
            "word: mio\n",
            "word: figlio\n",
            "word: di\n",
            "word: 3\n",
            "word: ha\n",
            "word: ufficialmente\n",
            "word: iniziato\n",
            "word: il\n",
            "word: suo\n",
            "word: periodo\n",
            "word: 'perchè\n",
            "word: '\n",
            "word: e\n",
            "word: sta\n",
            "word: già\n",
            "word: intuendo\n",
            "word: che\n",
            "word: spesso\n",
            "word: le\n",
            "word: risposte\n",
            "word: non\n",
            "word: rispondono\n",
            "sentence\n",
            "[  64 2356  203  361    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: ancora\n",
            "word: 32\n",
            "word: bella\n",
            "word: merda\n",
            "sentence\n",
            "[16068   369 16069 16070    63    16   485     3  2319     7     5     6\n",
            " 16071     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: malagiustizia\n",
            "word: italiana\n",
            "word: scaglia\n",
            "word: assolto\n",
            "word: dopo\n",
            "word: un\n",
            "word: anno\n",
            "word: di\n",
            "word: carcere\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: gkjo7gzjwr\n",
            "sentence\n",
            "[   14    57   112   431    22 16072    97   561    62    93   392     7\n",
            "     5     6 16073     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: per\n",
            "word: chi\n",
            "word: questa\n",
            "word: domenica\n",
            "word: si\n",
            "word: annoia\n",
            "word: nuovo\n",
            "word: post\n",
            "word: sul\n",
            "word: mio\n",
            "word: blog\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: r1dkl5igy8\n",
            "sentence\n",
            "[   36 16074   419   398    12   789 16075     8    12  2318   469     3\n",
            "   401    79 16076    14  6151    16   243 16077    16 16078     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: violalaviola\n",
            "word: sento\n",
            "word: freddo\n",
            "word: non\n",
            "word: trovo\n",
            "word: l'elastico\n",
            "word: e\n",
            "word: non\n",
            "word: c'ho\n",
            "word: voglia\n",
            "word: di\n",
            "word: uscire\n",
            "word: dal\n",
            "word: piumone\n",
            "word: per\n",
            "word: prenderne\n",
            "word: un\n",
            "word: altro\n",
            "word: uscitemi\n",
            "word: un\n",
            "word: elastico\n",
            "sentence\n",
            "[   73 16079  1145     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: oggi\n",
            "word: giornatata\n",
            "word: studio\n",
            "sentence\n",
            "[16080    45 16081     8    20  2364    22 16082     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: vedevo\n",
            "word: tutto\n",
            "word: sfuocato\n",
            "word: e\n",
            "word: i\n",
            "word: colori\n",
            "word: si\n",
            "word: mescolavano\n",
            "sentence\n",
            "[16083  1339   278    21    25    29   351   620    20 16084     9  2945\n",
            "     9  1675 16085     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ichnusa7\n",
            "word: concordo\n",
            "word: giusto\n",
            "word: ma\n",
            "word: anche\n",
            "word: una\n",
            "word: riforma\n",
            "word: elettorale\n",
            "word: i\n",
            "word: have\n",
            "word: a\n",
            "word: dream\n",
            "word: a\n",
            "word: partire\n",
            "word: dall'elettorato\n",
            "sentence\n",
            "[   36 16086   589     2 16087    18  1674     7     5     6 16088     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: smurfettevato\n",
            "word: controlla\n",
            "word: il\n",
            "word: cartellino\n",
            "word: del\n",
            "word: prezzo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: tnwmk7qulm\n",
            "sentence\n",
            "[16089 16090    44    92   220   799     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: gasparripdl\n",
            "word: gerrygreco\n",
            "word: ti\n",
            "word: hanno\n",
            "word: visto\n",
            "word: infatti\n",
            "sentence\n",
            "[16091  6152  2158 16092 16093  1426 16094  3274   680    32  1540   119\n",
            " 16095     8 16096     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: simonedica\n",
            "word: zazzaroni\n",
            "word: argomento\n",
            "word: delicato\n",
            "word: nervo\n",
            "word: scoperto\n",
            "word: discriminazione\n",
            "word: territoriale\n",
            "word: esiste\n",
            "word: da\n",
            "word: 150\n",
            "word: anni\n",
            "word: maleducazione\n",
            "word: e\n",
            "word: ignoranza\n",
            "sentence\n",
            "[   33 16097    30 16098     3 16099 16100    32    83   390  5945    51\n",
            " 16101   227    13     2    93    97 16102 16103     0     0     0     0\n",
            "     0]\n",
            "word: sono\n",
            "word: fissatissima\n",
            "word: con\n",
            "word: roar\n",
            "word: di\n",
            "word: katy\n",
            "word: perry\n",
            "word: da\n",
            "word: quando\n",
            "word: l'ho\n",
            "word: beccata\n",
            "word: su\n",
            "word: mtv\n",
            "word: ieri\n",
            "word: è\n",
            "word: il\n",
            "word: mio\n",
            "word: nuovo\n",
            "word: guilty\n",
            "word: pleasure\n",
            "sentence\n",
            "[16104    79  1888    13    29  1659    48    20  1630     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: warrior\n",
            "word: dal\n",
            "word: vivo\n",
            "word: è\n",
            "word: una\n",
            "word: meraviglia\n",
            "word: ho\n",
            "word: i\n",
            "word: brividi\n",
            "sentence\n",
            "[   36    20   498  1173  4003  6153  6154   650   335    21  6155   203\n",
            "    59    21   471    42  6155   203     7     5     6 16105     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: i\n",
            "word: live\n",
            "word: to\n",
            "word: read\n",
            "word: 'noi\n",
            "word: potterheads'\n",
            "word: pt\n",
            "word: 8\n",
            "word: ma\n",
            "word: quant'è\n",
            "word: bella\n",
            "word: no\n",
            "word: ma\n",
            "word: dico\n",
            "word: io\n",
            "word: quant'è\n",
            "word: bella\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: d0gsmwiy29\n",
            "sentence\n",
            "[   61  2034   137    12 16106 16107   541   128   304    30    20   473\n",
            "    10    22  5162    14    23   266     0     0     0     0     0     0\n",
            "     0]\n",
            "word: questo\n",
            "word: papa\n",
            "word: perchè\n",
            "word: non\n",
            "word: rinuncia\n",
            "word: l'8permille\n",
            "word: dello\n",
            "word: stato\n",
            "word: italiano\n",
            "word: con\n",
            "word: i\n",
            "word: cittadini\n",
            "word: che\n",
            "word: si\n",
            "word: suicidano\n",
            "word: per\n",
            "word: le\n",
            "word: tasse\n",
            "sentence\n",
            "[   66    13   301  2952   234   256    54    19   866   240     7     5\n",
            "     6 16108     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: berlusconi\n",
            "word: è\n",
            "word: appena\n",
            "word: entrato\n",
            "word: nei\n",
            "word: tt\n",
            "word: italia\n",
            "word: in\n",
            "word: posizione\n",
            "word: 10\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: vuwstpumy7\n",
            "sentence\n",
            "[   36 16109  6130 16110 16111  6131   531 16112     8  1778 16113     2\n",
            "  1951     7     5     6 16114 16115     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: mondopalloneit\n",
            "word: motogp\n",
            "word: phillip\n",
            "word: island\n",
            "word: marquez\n",
            "word: viene\n",
            "word: squalificato\n",
            "word: e\n",
            "word: lorenzo\n",
            "word: riapre\n",
            "word: il\n",
            "word: mondiale\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: rynwpkszkk\n",
            "word: mondopallone\n",
            "sentence\n",
            "[ 3268  3642    25     9    57    12    40  2368    21  1508    21    12\n",
            "    13   389   217   139    39 16116    53  1820  3262  3102    19  4650\n",
            "     0]\n",
            "word: messaggi\n",
            "word: privati\n",
            "word: anche\n",
            "word: a\n",
            "word: chi\n",
            "word: non\n",
            "word: ci\n",
            "word: segue\n",
            "word: ma\n",
            "word: seriamente\n",
            "word: ma\n",
            "word: non\n",
            "word: è\n",
            "word: possibile\n",
            "word: voglio\n",
            "word: dire\n",
            "word: come\n",
            "word: minimo\n",
            "word: gli\n",
            "word: account\n",
            "word: famosi\n",
            "word: andranno\n",
            "word: in\n",
            "word: tilt\n",
            "sentence\n",
            "[   36  4004     2   170  4499    20   297  2679    20   297  6156    20\n",
            "   297 16117 16118    13   577     7     5     6 16119     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: xjbeatrice\n",
            "word: il\n",
            "word: suo\n",
            "word: cappello\n",
            "word: i\n",
            "word: suoi\n",
            "word: occhiali\n",
            "word: i\n",
            "word: suoi\n",
            "word: tatuaggi\n",
            "word: i\n",
            "word: suoi\n",
            "word: shorts\n",
            "word: gialli\n",
            "word: è\n",
            "word: perfetto\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: rppmfbhjvg\n",
            "sentence\n",
            "[   36 16120    33   107  5567    10    31  1501     2  2416    19    16\n",
            " 16121    27 16122    30 16123     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: stosullescatole\n",
            "word: sono\n",
            "word: così\n",
            "word: sfigata\n",
            "word: che\n",
            "word: se\n",
            "word: metto\n",
            "word: il\n",
            "word: dito\n",
            "word: in\n",
            "word: un\n",
            "word: pagliaio\n",
            "word: mi\n",
            "word: pungo\n",
            "word: con\n",
            "word: l'ago\n",
            "sentence\n",
            "[   36 16124   145 16125     7     5     6 16126     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: zainshand\n",
            "word: sto\n",
            "word: soffrendo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: qnik5st0rb\n",
            "sentence\n",
            "[ 2759    65  1232   678 16127   246   192    22    55   514    13  6106\n",
            "   192   155     8  2759  6157  1129     0     0     0     0     0     0\n",
            "     0]\n",
            "word: dovremmo\n",
            "word: solo\n",
            "word: accettare\n",
            "word: ke\n",
            "word: qnd\n",
            "word: qualcuno\n",
            "word: nn\n",
            "word: si\n",
            "word: fa\n",
            "word: sentire\n",
            "word: è\n",
            "word: xké\n",
            "word: nn\n",
            "word: vuole\n",
            "word: e\n",
            "word: dovremmo\n",
            "word: lasciar\n",
            "word: perdere\n",
            "sentence\n",
            "[    2  1009  2964     3    16   124  5194     7     5     6 16128     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: potere\n",
            "word: vuoto\n",
            "word: di\n",
            "word: un\n",
            "word: paese\n",
            "word: fermo\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: epdaznp1ke\n",
            "sentence\n",
            "[   36 16129    12 16130   145    49     7     5     6 16131     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: meandliam\n",
            "word: non\n",
            "word: toccarmi\n",
            "word: sto\n",
            "word: bene\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 6xmh5cujr9\n",
            "sentence\n",
            "[ 27 114 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: mi\n",
            "word: piace\n",
            "word: troppo\n",
            "sentence\n",
            "[   34    19  1909    62  2351     9 16132    14     2   352 16133   154\n",
            "  2346   126   104    30    94 16134     0     0     0     0     0     0\n",
            "     0]\n",
            "word: tutti\n",
            "word: in\n",
            "word: piedi\n",
            "word: sul\n",
            "word: divano\n",
            "word: a\n",
            "word: tifare\n",
            "word: per\n",
            "word: il\n",
            "word: nostro\n",
            "word: gro15\n",
            "word: forza\n",
            "word: simo\n",
            "word: noi\n",
            "word: siamo\n",
            "word: con\n",
            "word: te\n",
            "word: vane\n",
            "sentence\n",
            "[16135   257   361     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: bebebebino\n",
            "word: buongiorno\n",
            "word: merda\n",
            "sentence\n",
            "[   27    13  1291    16   153     3   196     7     5     6 16136 16137\n",
            "  1068  3908 16138  3383   324 16139     0     0     0     0     0     0\n",
            "     0]\n",
            "word: mi\n",
            "word: è\n",
            "word: piaciuto\n",
            "word: un\n",
            "word: video\n",
            "word: di\n",
            "word: youtube\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: uhry3bqxzb\n",
            "word: draw\n",
            "word: my\n",
            "word: life\n",
            "word: kratos\n",
            "word: god\n",
            "word: of\n",
            "word: war\n",
            "sentence\n",
            "[   11  1147  1560 16140     3   177    70     7     5     6 16141     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: la\n",
            "word: vostra\n",
            "word: stella\n",
            "word: l'oroscopo\n",
            "word: di\n",
            "word: domani\n",
            "word: 3\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: zylruvi26t\n",
            "sentence\n",
            "[   36 16142    26  6158     3    75    22    13 16143    11 16144     3\n",
            "  6140    12 16145    38    26 16146   963   804  1031  6071     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: angeaifa\n",
            "word: al\n",
            "word: degrado\n",
            "word: di\n",
            "word: roma\n",
            "word: si\n",
            "word: è\n",
            "word: aggiunta\n",
            "word: la\n",
            "word: devastazione\n",
            "word: di\n",
            "word: 19o\n",
            "word: non\n",
            "word: accadrà\n",
            "word: più\n",
            "word: al\n",
            "word: vaglio\n",
            "word: provvedimenti\n",
            "word: anti\n",
            "word: manifestazione\n",
            "word: st\n",
            "sentence\n",
            "[16147 16148 16149  2153  1320     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: sophie\n",
            "word: always\n",
            "word: owwwwwwww\n",
            "word: quanti\n",
            "word: ricordi\n",
            "sentence\n",
            "[16150 16151   285 16152   241    23   415  4005  1170     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: stylinshivers\n",
            "word: rebelljon\n",
            "word: posso\n",
            "word: chiedervi\n",
            "word: dove\n",
            "word: le\n",
            "word: avete\n",
            "word: prese\n",
            "word: hahaha\n",
            "sentence\n",
            "[   36 16153 16154   715 16155   672    19    54   370    48   334    77\n",
            "  6159     3  6160     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: amedeotomanelli\n",
            "word: angelacasciaro\n",
            "word: m\n",
            "word: giul\n",
            "word: diritto\n",
            "word: in\n",
            "word: italia\n",
            "word: ah\n",
            "word: ho\n",
            "word: capito\n",
            "word: sei\n",
            "word: maestro\n",
            "word: di\n",
            "word: tennis\n",
            "sentence\n",
            "[16156   176   201     2   224 16157   510  5373     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: pascale\n",
            "word: amore\n",
            "word: vero\n",
            "word: il\n",
            "word: mondo\n",
            "word: intero\n",
            "word: chiede\n",
            "word: certezze\n",
            "sentence\n",
            "[16158    30   299 16159  1658   126   299 16160   190    19  1308    51\n",
            "   465   451     2  1352 16161  2262     3  2394   465     7     5     6\n",
            " 16162]\n",
            "word: pezzali\n",
            "word: con\n",
            "word: '\n",
            "word: l'universo\n",
            "word: tranne\n",
            "word: noi\n",
            "word: '\n",
            "word: �\n",
            "word: adesso\n",
            "word: in\n",
            "word: onda\n",
            "word: su\n",
            "word: radio\n",
            "word: amici\n",
            "word: il\n",
            "word: canale\n",
            "word: pop\n",
            "word: rock\n",
            "word: di\n",
            "word: pratica\n",
            "word: radio\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: 3gbeddqx3i\n",
            "sentence\n",
            "[ 1078    21    42   471   417     9   244     8    12    22    55    16\n",
            " 16164   145     9   199  4006    29 16165     8   782   242    23  2990\n",
            " 16166]\n",
            "word: compiti\n",
            "word: ma\n",
            "word: io\n",
            "word: dico\n",
            "word: vado\n",
            "word: a\n",
            "word: scuola\n",
            "word: e\n",
            "word: non\n",
            "word: si\n",
            "word: fa\n",
            "word: un\n",
            "word: tubo\n",
            "word: sto\n",
            "word: a\n",
            "word: casa\n",
            "word: malata\n",
            "word: una\n",
            "word: sett\n",
            "word: e\n",
            "word: danno\n",
            "word: tutte\n",
            "word: le\n",
            "word: verifiche\n",
            "word: 😡\n",
            "sentence\n",
            "[  24   95 4403   27 5414  101    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: della\n",
            "word: mia\n",
            "word: determinazione\n",
            "word: mi\n",
            "word: piaci\n",
            "word: tu\n",
            "sentence\n",
            "[   36 16167    13    11   420    38   203     3    61   224 16168     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: bertosvojce\n",
            "word: è\n",
            "word: la\n",
            "word: mamma\n",
            "word: più\n",
            "word: bella\n",
            "word: di\n",
            "word: questo\n",
            "word: mondo\n",
            "word: felizdiamamabertotti\n",
            "sentence\n",
            "[16169    22    22    89    22  2219  1764 16170   162    11  5704     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: agorapolitica\n",
            "word: si\n",
            "word: si\n",
            "word: quello\n",
            "word: si\n",
            "word: peró\n",
            "word: bisognerebbe\n",
            "word: inquadrare\n",
            "word: meglio\n",
            "word: la\n",
            "word: realtá\n",
            "sentence\n",
            "[   36 16171    36   486     8    44   468 16172  2379     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: emptjness\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: seguo\n",
            "word: daidai💕\n",
            "word: 02\n",
            "sentence\n",
            "[   36 16173    11 16174 16175    14    53 16176    32 16177    35 16178\n",
            "     7     5     6 16179     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: tuttogreen\n",
            "word: la\n",
            "word: casetta\n",
            "word: nido\n",
            "word: per\n",
            "word: gli\n",
            "word: uccellini\n",
            "word: da\n",
            "word: appendere\n",
            "word: alla\n",
            "word: finestra\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: spasuicavc\n",
            "sentence\n",
            "[   10   431 16180     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: che\n",
            "word: domenica\n",
            "word: pallosa\n",
            "sentence\n",
            "[  207  6122   420     9 16181    26 16182     3  4007     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: devo\n",
            "word: convincere\n",
            "word: mamma\n",
            "word: a\n",
            "word: mandarmi\n",
            "word: al\n",
            "word: party\n",
            "word: di\n",
            "word: halloween\n",
            "sentence\n",
            "[16183    22   146 16184   483    31    44  3581    86    63    21   830\n",
            "     9   199     3  2882     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: pacjfic\n",
            "word: si\n",
            "word: molto\n",
            "word: asgjvf\n",
            "word: scusa\n",
            "word: se\n",
            "word: ti\n",
            "word: rispondo\n",
            "word: sempre\n",
            "word: dopo\n",
            "word: ma\n",
            "word: stavo\n",
            "word: a\n",
            "word: casa\n",
            "word: di\n",
            "word: amiche\n",
            "sentence\n",
            "[   36 16185    36   486     8    44   468  4008     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: xzaynssmilex\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: seguo\n",
            "word: x9\n",
            "sentence\n",
            "[   36 16186    19    54    40    33    73    29 16187     3 16188    14\n",
            "     2 16189    21    65   679    33 16190     7     5     6 16191     0\n",
            "     0]\n",
            "word: rt\n",
            "word: wireditalia\n",
            "word: in\n",
            "word: italia\n",
            "word: ci\n",
            "word: sono\n",
            "word: oggi\n",
            "word: una\n",
            "word: trentina\n",
            "word: di\n",
            "word: piattaforme\n",
            "word: per\n",
            "word: il\n",
            "word: crowdfunding\n",
            "word: ma\n",
            "word: solo\n",
            "word: 23\n",
            "word: sono\n",
            "word: attive\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: kpfip3ax3z\n",
            "sentence\n",
            "[  20  339  604  451   32   73   19   82  455   20 2927  180 2008    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: i\n",
            "word: miei\n",
            "word: migliori\n",
            "word: amici\n",
            "word: da\n",
            "word: oggi\n",
            "word: in\n",
            "word: poi\n",
            "word: saranno\n",
            "word: i\n",
            "word: fazzoletti\n",
            "word: lt\n",
            "word: 33\n",
            "sentence\n",
            "[    2   352     4   184  2200     7     5     6 16192     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: il\n",
            "word: nostro\n",
            "word: governo\n",
            "word: deve\n",
            "word: riflettere\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: v2mds4qc4o\n",
            "sentence\n",
            "[  207   953    16   836     3  1116    73 16193     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: devo\n",
            "word: studiare\n",
            "word: un\n",
            "word: casino\n",
            "word: di\n",
            "word: roba\n",
            "word: oggi\n",
            "word: 😪\n",
            "sentence\n",
            "[16194    19   362   413   255   887    11   667   169 16195     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ehisoul\n",
            "word: in\n",
            "word: caso\n",
            "word: qualche\n",
            "word: volta\n",
            "word: facciamo\n",
            "word: la\n",
            "word: web\n",
            "word: hai\n",
            "word: ovo\n",
            "sentence\n",
            "[   83  1293     8  3337    22 16196 16197    11  3742 16198     7     5\n",
            "     6 16199     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: quando\n",
            "word: massa\n",
            "word: e\n",
            "word: siena\n",
            "word: si\n",
            "word: litigavano\n",
            "word: vetulonia\n",
            "word: la\n",
            "word: colonna\n",
            "word: etrusca\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: tyrqj9o80j\n",
            "sentence\n",
            "[  277 16200    26 16201    61    13    16 16202 16203     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: pure\n",
            "word: macklemore\n",
            "word: al\n",
            "word: 27°\n",
            "word: questo\n",
            "word: è\n",
            "word: un\n",
            "word: oltraggio\n",
            "word: eurotopchart\n",
            "sentence\n",
            "[   36  2397   432   305     3  1823    19   231    29   774   164   147\n",
            "  6161   340 16204   968    10    11  6161   527    12  6162   518     0\n",
            "     0]\n",
            "word: rt\n",
            "word: tweetcomici\n",
            "word: quel\n",
            "word: momento\n",
            "word: di\n",
            "word: panico\n",
            "word: in\n",
            "word: cui\n",
            "word: una\n",
            "word: canzone\n",
            "word: parte\n",
            "word: dalla\n",
            "word: cuffia\n",
            "word: sinistra\n",
            "word: facendoti\n",
            "word: credere\n",
            "word: che\n",
            "word: la\n",
            "word: cuffia\n",
            "word: destra\n",
            "word: non\n",
            "word: funzioni\n",
            "word: …\n",
            "sentence\n",
            "[  257 16205 16206    49   112   319    30    16    36   486     8    44\n",
            " 16207    22 16208 16209     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: buongiorno\n",
            "word: mondoooo\n",
            "word: iniziamo\n",
            "word: bene\n",
            "word: questa\n",
            "word: giornata\n",
            "word: con\n",
            "word: un\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: riseguo\n",
            "word: si\n",
            "word: parteeeeeeee\n",
            "word: jbboy\n",
            "sentence\n",
            "[16210   682    14 16211     2  6149     3    45    23   186   160  2343\n",
            "    22   232  5851    31    11  4009    32 16212   364     3   693     0\n",
            "     0]\n",
            "word: stephanssmile\n",
            "word: ahahahah\n",
            "word: per\n",
            "word: talete\n",
            "word: il\n",
            "word: principio\n",
            "word: di\n",
            "word: tutto\n",
            "word: le\n",
            "word: cose\n",
            "word: era\n",
            "word: l'acqua\n",
            "word: si\n",
            "word: sarebbe\n",
            "word: spento\n",
            "word: se\n",
            "word: la\n",
            "word: guardi\n",
            "word: da\n",
            "word: quest'altro\n",
            "word: punto\n",
            "word: di\n",
            "word: vista\n",
            "sentence\n",
            "[   14   310  2822   711    93  1875    13  3988     8    30    24 16213\n",
            "  1678     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: per\n",
            "word: quale\n",
            "word: assurdo\n",
            "word: motivo\n",
            "word: mio\n",
            "word: fratello\n",
            "word: è\n",
            "word: nudo\n",
            "word: e\n",
            "word: con\n",
            "word: della\n",
            "word: farina\n",
            "word: addosso\n",
            "sentence\n",
            "[   36 16214   357     3   696   583    44   655   597    19   681 16215\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: thanksstephan\n",
            "word: auguri\n",
            "word: di\n",
            "word: cuore\n",
            "word: ♥\n",
            "word: ti\n",
            "word: vogliamo\n",
            "word: presto\n",
            "word: in\n",
            "word: campo\n",
            "word: happybdaymattiadesciglio\n",
            "sentence\n",
            "[   36 16216    31     9    16  1151   114 16217 16218  1335    16    93\n",
            " 16219  6163   353     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: sheeransradio\n",
            "word: se\n",
            "word: a\n",
            "word: un\n",
            "word: ragazzo\n",
            "word: piace\n",
            "word: ligabue\n",
            "word: automaticamente\n",
            "word: diventa\n",
            "word: un\n",
            "word: mio\n",
            "word: potenziale\n",
            "word: marito\n",
            "word: sapevatelo\n",
            "sentence\n",
            "[16220    10   314    33    32    94 16221     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: vodkdream\n",
            "word: che\n",
            "word: ore\n",
            "word: sono\n",
            "word: da\n",
            "word: te\n",
            "word: ahhahaha\n",
            "sentence\n",
            "[4002   11  205 3617   27   55 3902   70    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: 10cosesulragazzochemipiace\n",
            "word: la\n",
            "word: sua\n",
            "word: risata\n",
            "word: mi\n",
            "word: fa\n",
            "word: impazzire\n",
            "word: 3\n",
            "sentence\n",
            "[16222  1500    46   337  2399   180    70     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: onedautograph\n",
            "word: aw\n",
            "word: grazie\n",
            "word: mille\n",
            "word: dolcezza\n",
            "word: lt\n",
            "word: 3\n",
            "sentence\n",
            "[ 2869 16223     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: skysport\n",
            "word: coraggiosa\n",
            "sentence\n",
            "[16224 16225   165  1773     8   165  2857     7     5     6 16226     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: incidenti\n",
            "word: stradali\n",
            "word: due\n",
            "word: morti\n",
            "word: e\n",
            "word: due\n",
            "word: gravi\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: ewbjemaqmo\n",
            "sentence\n",
            "[6164   61   46   13   14   94 2976    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "word: marcocarta6annidinoi\n",
            "word: questo\n",
            "word: grazie\n",
            "word: è\n",
            "word: per\n",
            "word: te\n",
            "word: artista\n",
            "sentence\n",
            "[ 12  13 897 459   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: non\n",
            "word: è\n",
            "word: abbastanza\n",
            "word: forte\n",
            "sentence\n",
            "[   36 16227    44   217    49 16228     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: horanhugsme\n",
            "word: ti\n",
            "word: voglio\n",
            "word: bene\n",
            "word: styleshire\n",
            "sentence\n",
            "[16229     9  5608 16230 16231  1406    76    27   159    31    44 16232\n",
            "     7     5     6 16233 16234 16235 16236     0     0     0     0     0\n",
            "     0]\n",
            "word: terzapagina\n",
            "word: a\n",
            "word: lecce\n",
            "word: walter\n",
            "word: spennato\n",
            "word: presenta\n",
            "word: quanto\n",
            "word: mi\n",
            "word: dai\n",
            "word: se\n",
            "word: ti\n",
            "word: uccido\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: td5j2hjjj7\n",
            "word: lecceprima\n",
            "word: besa\n",
            "word: controluce\n",
            "sentence\n",
            "[16237   145   435 16238    19  5102     8     2    93  1137    85  1653\n",
            "     9   841  1171     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: xloujsvans\n",
            "word: sto\n",
            "word: facendo\n",
            "word: l'imperativo\n",
            "word: in\n",
            "word: spagnolo\n",
            "word: e\n",
            "word: il\n",
            "word: mio\n",
            "word: cervello\n",
            "word: sta\n",
            "word: andando\n",
            "word: a\n",
            "word: fuoco\n",
            "word: cc\n",
            "sentence\n",
            "[   38    10 16239    53   138    33 16240     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: più\n",
            "word: che\n",
            "word: bipolaristi\n",
            "word: gli\n",
            "word: italiani\n",
            "word: sono\n",
            "word: bipolari\n",
            "sentence\n",
            "[   20  4010 16241     7     5     6 16242    47   196     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: i\n",
            "word: fratelli\n",
            "word: rosselli\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: afrofonpp9\n",
            "word: via\n",
            "word: youtube\n",
            "sentence\n",
            "[101   3  45  61 174  12 169 334 168   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0]\n",
            "word: tu\n",
            "word: di\n",
            "word: tutto\n",
            "word: questo\n",
            "word: tempo\n",
            "word: non\n",
            "word: hai\n",
            "word: capito\n",
            "word: niente\n",
            "sentence\n",
            "[   73  1585    32  1312 16243 16244     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: oggi\n",
            "word: pranzo\n",
            "word: da\n",
            "word: nonna\n",
            "word: tornerò\n",
            "word: rotolando\n",
            "sentence\n",
            "[ 6165  2390   535    25    42   145 16245    70     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: prfzjm\n",
            "word: wow\n",
            "word: cmq\n",
            "word: anche\n",
            "word: io\n",
            "word: sto\n",
            "word: bn\n",
            "word: 3\n",
            "sentence\n",
            "[16246 16247   483  1907   878   267     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rihsvodka\n",
            "word: drunkofrih\n",
            "word: scusa\n",
            "word: avrò\n",
            "word: sbagliato\n",
            "word: foto\n",
            "sentence\n",
            "[16248    55    23  5059 16249     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: paulwukgdr\n",
            "word: fa\n",
            "word: le\n",
            "word: capriole\n",
            "word: all'indietro\n",
            "sentence\n",
            "[16250     8  6166    26  3651    10   139   896    35 16251     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: peperoni\n",
            "word: e\n",
            "word: patate\n",
            "word: al\n",
            "word: forno\n",
            "word: che\n",
            "word: dire\n",
            "word: complimenti\n",
            "word: alla\n",
            "word: cuoca\n",
            "sentence\n",
            "[  312    10    22    13  1921     2  2722    12    27   574   217     2\n",
            " 16252  4505     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: quella\n",
            "word: che\n",
            "word: si\n",
            "word: è\n",
            "word: presa\n",
            "word: il\n",
            "word: gatto\n",
            "word: non\n",
            "word: mi\n",
            "word: chiama\n",
            "word: voglio\n",
            "word: il\n",
            "word: gattoooo\n",
            "word: zoccola\n",
            "sentence\n",
            "[16253     2    93 16254  2358    13 16255    56   373  5721    73    81\n",
            "  6167    32   177     9  2226  5907 16256     0     0     0     0     0\n",
            "     0]\n",
            "word: fiorentinajuventus\n",
            "word: il\n",
            "word: mio\n",
            "word: ortolano\n",
            "word: preferito\n",
            "word: è\n",
            "word: juventino\n",
            "word: cosa\n",
            "word: spero\n",
            "word: succeda\n",
            "word: oggi\n",
            "word: perché\n",
            "word: continui\n",
            "word: da\n",
            "word: domani\n",
            "word: a\n",
            "word: proporre\n",
            "word: verdure\n",
            "word: fresche\n",
            "sentence\n",
            "[16257    10  6168     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: matteopeverini\n",
            "word: che\n",
            "word: emozione\n",
            "sentence\n",
            "[16258     7     5     6 16259    59   145   151    33   173  1828     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: seyna015\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: mby1mijixg\n",
            "word: no\n",
            "word: sto\n",
            "word: male\n",
            "word: sono\n",
            "word: troppo\n",
            "word: belli\n",
            "sentence\n",
            "[   36 16260   207  1508  1636    20  1078     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: lovemarchisjo\n",
            "word: devo\n",
            "word: seriamente\n",
            "word: iniziare\n",
            "word: i\n",
            "word: compiti\n",
            "sentence\n",
            "[  240 16261  2018    10    12    44  3261     7     5     6 16262     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: 10\n",
            "word: doppi\n",
            "word: sensi\n",
            "word: che\n",
            "word: non\n",
            "word: ti\n",
            "word: aspetti\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: bjnkthpu04\n",
            "sentence\n",
            "[16263  1725    46   180    70   289    14     2   602   485     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: zaynsmovie\n",
            "word: aww\n",
            "word: grazie\n",
            "word: lt\n",
            "word: 3\n",
            "word: speriamo\n",
            "word: per\n",
            "word: il\n",
            "word: prossimo\n",
            "word: anno\n",
            "sentence\n",
            "[   36 16264    76   113   100   577     2  3288     3  2965     2  1262\n",
            "  3288     3    86     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: xzajnsljps\n",
            "word: quanto\n",
            "word: può\n",
            "word: essere\n",
            "word: perfetto\n",
            "word: il\n",
            "word: cast\n",
            "word: di\n",
            "word: glee\n",
            "word: il\n",
            "word: miglior\n",
            "word: cast\n",
            "word: di\n",
            "word: sempre\n",
            "sentence\n",
            "[ 3886  1473    53  3468    14  2938  6169    18  5397 16265   380    14\n",
            "     2  6170    18  3435     7     5     6 16266     0     0     0     0\n",
            "     0]\n",
            "word: apple\n",
            "word: aumenta\n",
            "word: gli\n",
            "word: ordini\n",
            "word: per\n",
            "word: l'iphone\n",
            "word: 5s\n",
            "word: del\n",
            "word: 75\n",
            "word: riducendo\n",
            "word: quelli\n",
            "word: per\n",
            "word: il\n",
            "word: 5c\n",
            "word: del\n",
            "word: 35\n",
            "word: http\n",
            "word: t\n",
            "word: co\n",
            "word: utxagv8ins\n",
            "sentence\n",
            "[16267   140 16268    77 16269     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: soproudofoned\n",
            "word: nella\n",
            "word: sfortuna\n",
            "word: sei\n",
            "word: fortunata\n",
            "sentence\n",
            "[   36 16270  6171    48    16   691   291    31    16  1151    12    28\n",
            "   379   391   119   802    12    27   114     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: livinonamishax\n",
            "word: 20thingsaboutme\n",
            "word: ho\n",
            "word: un\n",
            "word: serio\n",
            "word: problema\n",
            "word: se\n",
            "word: un\n",
            "word: ragazzo\n",
            "word: non\n",
            "word: ha\n",
            "word: almeno\n",
            "word: 30\n",
            "word: anni\n",
            "word: sicuro\n",
            "word: non\n",
            "word: mi\n",
            "word: piace\n",
            "sentence\n",
            "[   36 16271  2634  6172    77 16272  1985    33  6173    39 16273    18\n",
            "   502    10    85    30  1513    81    37  1255   148     8 16274     0\n",
            "     0]\n",
            "word: rt\n",
            "word: stylinsl0ve\n",
            "word: congratulazioni\n",
            "word: jay\n",
            "word: sei\n",
            "word: incint\n",
            "word: sisi\n",
            "word: sono\n",
            "word: felicissima\n",
            "word: come\n",
            "word: eleanor\n",
            "word: del\n",
            "word: resto\n",
            "word: che\n",
            "word: sta\n",
            "word: con\n",
            "word: louis\n",
            "word: perché\n",
            "word: lo\n",
            "word: ama\n",
            "word: tanto\n",
            "word: e\n",
            "word: l…\n",
            "sentence\n",
            "[   91   271   533    10  5912    12  2284     3    56 16275  1257  2944\n",
            "   242     3   100 16276     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ad\n",
            "word: ogni\n",
            "word: ragazza\n",
            "word: che\n",
            "word: soffre\n",
            "word: non\n",
            "word: importa\n",
            "word: di\n",
            "word: cosa\n",
            "word: chiedete\n",
            "word: aiuto\n",
            "word: meritate\n",
            "word: tutte\n",
            "word: di\n",
            "word: essere\n",
            "word: salvate\n",
            "sentence\n",
            "[16277   509    42   481    14    68    11   431    13   270   903     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: ioamokilla\n",
            "word: neanche\n",
            "word: io\n",
            "word: quindi\n",
            "word: per\n",
            "word: me\n",
            "word: la\n",
            "word: domenica\n",
            "word: è\n",
            "word: ok\n",
            "word: ahaha\n",
            "sentence\n",
            "[   36 16278    12   320    10    20   375 16279  2778   314     3  6073\n",
            "    92  3613  3834     9   312     3    16 16280 16281     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: larrysl0ver\n",
            "word: non\n",
            "word: credo\n",
            "word: che\n",
            "word: i\n",
            "word: ragazzi\n",
            "word: reggeranno\n",
            "word: sette\n",
            "word: ore\n",
            "word: di\n",
            "word: twitcam\n",
            "word: hanno\n",
            "word: l'attenzione\n",
            "word: pari\n",
            "word: a\n",
            "word: quella\n",
            "word: di\n",
            "word: un\n",
            "word: bradipo\n",
            "word: addormentato\n",
            "sentence\n",
            "[ 6171   650   110    31    27   367    51    29    56  6174    12    11\n",
            " 16282  6175    14  6176     0     0     0     0     0     0     0     0\n",
            "     0]\n",
            "word: 20thingsaboutme\n",
            "word: pt\n",
            "word: 2\n",
            "word: se\n",
            "word: mi\n",
            "word: fisso\n",
            "word: su\n",
            "word: una\n",
            "word: cosa\n",
            "word: finchè\n",
            "word: non\n",
            "word: la\n",
            "word: ottengo\n",
            "word: lotto\n",
            "word: per\n",
            "word: averla\n",
            "sentence\n",
            "[   36   132 16283    57   155  1282  4921     9    68    36   486     8\n",
            "    44   468    35  3998    24   893     0     0     0     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: x\n",
            "word: aly\n",
            "word: chi\n",
            "word: vuole\n",
            "word: aumentare\n",
            "word: assieme\n",
            "word: a\n",
            "word: me\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: seguo\n",
            "word: alla\n",
            "word: velocità\n",
            "word: della\n",
            "word: luce\n",
            "sentence\n",
            "[   36 16284    36   486     8    44   468    19    38    44   263     2\n",
            "   430    19 16285 16286 16287 16288 16289 16290 16291     0     0     0\n",
            "     0]\n",
            "word: rt\n",
            "word: heakalove\n",
            "word: rt\n",
            "word: seguimi\n",
            "word: e\n",
            "word: ti\n",
            "word: seguo\n",
            "word: in\n",
            "word: più\n",
            "word: ti\n",
            "word: voto\n",
            "word: il\n",
            "word: profilo\n",
            "word: in\n",
            "word: 🌕perfetto\n",
            "word: 🌔bellissimo\n",
            "word: 🌓bello\n",
            "word: 🌒carino\n",
            "word: 🌑consiglio\n",
            "word: cambialo\n",
            "word: x7\n",
            "sentence\n",
            "[16292   662  1131   101     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4c0a08443f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word: '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwKieOm1Vg1n",
        "outputId": "44e7c7b0-77a3-4784-9cfb-47c8491d03ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7410, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model = model.fit(x_train_emb,np.array(train[\"opos\"]))"
      ],
      "metadata": {
        "id": "6n3LlvjzSH8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_emb = []\n",
        "for sentence in x_test:\n",
        "  sent_emb = [0 for k in range(300)] \n",
        "  num_tok = 0\n",
        "  for tok in sentence:\n",
        "    if tok != 0:\n",
        "      word=list(word_index.keys())[list(word_index.values()).index(tok)]\n",
        "      try:\n",
        "          emb = word2vec_model300.wv[word]\n",
        "          sent_emb = [x + y for x, y in zip(sent_emb, emb)]\n",
        "          num_tok = num_tok +1\n",
        "      except:\n",
        "          pass\n",
        "  if num_tok != 0:\n",
        "    final_sent_emb = [x / num_tok for x in sent_emb]     \n",
        "  else:\n",
        "    final_sent_emb = sent_emb  \n",
        "\n",
        "  x_test_emb.append(final_sent_emb)  \n",
        "\n",
        "x_test_emb = np.array(x_test_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNqtp0_3bFT8",
        "outputId": "341da0f7-fa77-426a-fcb0-5d6b3ba9b355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-b3d4e5236a1a>:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  emb = word2vec_model300.wv[word]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_emb[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkkgFpiZc4Ae",
        "outputId": "5065a7d9-c511-4c21-8281-f04f25217c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.10583496,  0.17346191, -0.04200963,  0.10374233, -0.11962891,\n",
              "        0.17735073,  0.00624738, -0.02585275,  0.06591797,  0.05543736,\n",
              "       -0.14481027, -0.13745117, -0.23883929, -0.02305385, -0.08729771,\n",
              "        0.2122661 ,  0.10132708,  0.24436733,  0.0561894 ,  0.03029088,\n",
              "       -0.14454869, -0.08150809,  0.21833147,  0.05906459, -0.11914062,\n",
              "       -0.13428824, -0.06111363,  0.19949777, -0.15171596, -0.03703526,\n",
              "        0.0246582 ,  0.13567243,  0.02382551, -0.11489432, -0.10062081,\n",
              "        0.01499721, -0.15104893,  0.16149902,  0.17180525, -0.06269182,\n",
              "       -0.05664062, -0.09280831,  0.05502755,  0.08325195,  0.01702009,\n",
              "       -0.13068499, -0.04554967,  0.00729806, -0.16492571,  0.16476004,\n",
              "       -0.23479353,  0.26789202,  0.05348424,  0.21290806, -0.15265765,\n",
              "        0.09912109, -0.13092913, -0.15757533, -0.00468227, -0.11165946,\n",
              "       -0.18324498,  0.21424648, -0.04246303, -0.06439645,  0.03559658,\n",
              "       -0.17328753, -0.11858259, -0.10718209,  0.10501535,  0.1940918 ,\n",
              "       -0.0304827 ,  0.00620161, -0.00155204,  0.06408691, -0.0811942 ,\n",
              "       -0.01611328,  0.11429269,  0.125     , -0.04999651,  0.00324358,\n",
              "       -0.06643677, -0.02709961,  0.0617327 , -0.15499442,  0.10367257,\n",
              "        0.09556362, -0.03619385,  0.24093192, -0.04998779, -0.03272356,\n",
              "       -0.11314174, -0.05684989, -0.08872768, -0.14456613,  0.22251674,\n",
              "       -0.0275007 , -0.08393206, -0.03839983,  0.21747698, -0.04820251,\n",
              "       -0.15910993, -0.03703962, -0.07495117,  0.05378069, -0.13874163,\n",
              "        0.22719029, -0.1104126 ,  0.03381348, -0.06801496,  0.20574079,\n",
              "        0.00896781, -0.27887835,  0.14805385, -0.09953962,  0.03843471,\n",
              "        0.05746896, -0.04042271, -0.19907924,  0.09866769,  0.03251866,\n",
              "        0.0125558 , -0.10243443, -0.09441267,  0.04166085,  0.20204381,\n",
              "       -0.24899728, -0.18289621,  0.01946967, -0.0118103 ,  0.12106759,\n",
              "       -0.17131696,  0.05911691,  0.11784581,  0.03515625, -0.07042585,\n",
              "        0.00548335, -0.01719448, -0.09526716,  0.23964146,  0.04893276,\n",
              "        0.19482422, -0.16810826, -0.05540248,  0.105399  , -0.03512137,\n",
              "       -0.03018624, -0.07366943,  0.09895543, -0.05186244, -0.17499651,\n",
              "        0.05833217, -0.19614955,  0.03297642, -0.04069301,  0.00925991,\n",
              "       -0.12146868,  0.06866455,  0.43631417,  0.08989607, -0.09449986,\n",
              "        0.01828875,  0.09329224, -0.07139369,  0.06321498,  0.02243478,\n",
              "       -0.1472168 ,  0.09986006,  0.0507115 , -0.14937919,  0.17480469,\n",
              "       -0.16071429, -0.03088379,  0.01919665, -0.0325579 ,  0.05747768,\n",
              "        0.08932059,  0.19719587, -0.22987584,  0.06905692, -0.12172154,\n",
              "        0.01834542,  0.04117257,  0.05412946,  0.01886858,  0.11056083,\n",
              "        0.16420201, -0.04700579,  0.02995954, -0.01350621,  0.00351279,\n",
              "        0.05452183,  0.0105678 , -0.17224121,  0.00613403,  0.05681501,\n",
              "        0.04377093, -0.04272461, -0.05208915,  0.08025251,  0.12300764,\n",
              "        0.01978847,  0.09887586, -0.14679609, -0.09399414,  0.24776786,\n",
              "       -0.16179548,  0.01048061,  0.02165876, -0.17872184,  0.09737723,\n",
              "        0.12461635, -0.04927717, -0.21735491,  0.19538225, -0.08909171,\n",
              "        0.00913783,  0.02613177, -0.11317662, -0.16850063,  0.03834752,\n",
              "        0.03041295,  0.07179478,  0.10229492,  0.04261126,  0.04912022,\n",
              "       -0.19841657,  0.0884661 ,  0.09952218, -0.04483468, -0.04119001,\n",
              "       -0.07039097, -0.125     , -0.12629046, -0.05934361,  0.02265276,\n",
              "       -0.00700678, -0.06773158,  0.05564662,  0.01810128,  0.01599121,\n",
              "        0.03941127, -0.16929408,  0.15961565,  0.0359933 , -0.00821359,\n",
              "        0.05639648, -0.03177316,  0.14668492, -0.01342991, -0.14906529,\n",
              "        0.1267613 ,  0.07773481,  0.0871582 , -0.03111485,  0.03998675,\n",
              "       -0.09615653, -0.12737165, -0.04998779, -0.03076172,  0.09807478,\n",
              "        0.0194615 ,  0.12970407,  0.253976  , -0.06217739, -0.01262556,\n",
              "       -0.10667419, -0.06371198,  0.02252633, -0.05449568, -0.130576  ,\n",
              "       -0.00340925, -0.13546317,  0.00619943,  0.03491211,  0.18181501,\n",
              "        0.00975691, -0.25010463, -0.1517007 , -0.11615862,  0.09938921,\n",
              "       -0.15611049,  0.21556963, -0.04493059,  0.03945487,  0.1527601 ,\n",
              "        0.06169782,  0.0385328 ,  0.03353446, -0.06347656, -0.00550188,\n",
              "       -0.06938825, -0.02317592,  0.00556728,  0.25027902,  0.04858398,\n",
              "       -0.09026228, -0.03674316, -0.09139579, -0.12196568,  0.12163435])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K_HRCp6bybw",
        "outputId": "4135f7a7-89f1-483c-8119-a0d4dabf6ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_emb)"
      ],
      "metadata": {
        "id": "5FXgZRTlbNrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQE1wzKIb30p",
        "outputId": "c1bec281-6b9a-408e-b9ea-e3425bfdb493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),predictions,digits=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmZG7RV5bSgn",
        "outputId": "bc249dc4-9d9c-422c-b79a-23bad3204850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.85818   0.78944   0.82238      1648\n",
            "           1    0.28306   0.38920   0.32775       352\n",
            "\n",
            "    accuracy                        0.71900      2000\n",
            "   macro avg    0.57062   0.58932   0.57506      2000\n",
            "weighted avg    0.75696   0.71900   0.73532      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier(10)\n",
        "\n",
        "# Train the model using the training sets\n",
        "model = model.fit(x_train_emb,np.array(train[\"opos\"]))"
      ],
      "metadata": {
        "id": "w0xJQ9mDffiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_emb)"
      ],
      "metadata": {
        "id": "j5H9BCxofuJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),predictions,digits=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEOhEkEafvi6",
        "outputId": "821a729e-e3be-4f60-cfb8-11338f755c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.83221   0.97816   0.89930      1648\n",
            "           1    0.42857   0.07670   0.13012       352\n",
            "\n",
            "    accuracy                        0.81950      2000\n",
            "   macro avg    0.63039   0.52743   0.51471      2000\n",
            "weighted avg    0.76117   0.81950   0.76393      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model = model.fit(x_train_emb,np.array(train[\"opos\"]))"
      ],
      "metadata": {
        "id": "mfN_emwwfx8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test_emb)"
      ],
      "metadata": {
        "id": "2F-2YE2Jf7R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),predictions,digits=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qoVT--lf8cM",
        "outputId": "9723d8b0-6edc-46ee-8589-e75e350272ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.83207   0.99818   0.90759      1648\n",
            "           1    0.86957   0.05682   0.10667       352\n",
            "\n",
            "    accuracy                        0.83250      2000\n",
            "   macro avg    0.85082   0.52750   0.50713      2000\n",
            "weighted avg    0.83867   0.83250   0.76662      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oShKBBdVrQxD"
      },
      "source": [
        "### A simple supervised model in Keras\n",
        "\n",
        "The following computes a very simple model:\n",
        "\n",
        "<img src=\"https://m2dsupsdlclass.github.io/lectures-labs/slides/06_deep_nlp/images/fasttext.svg\" style=\"width: 600px;\" />\n",
        "\n",
        "- Build an embedding layer mapping each word to a vector representation\n",
        "- Compute the vector representation of all words in each sequence and average them\n",
        "- Add a dense layer to output 20 classes (+ softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "6lnA30CarQxE"
      },
      "source": [
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, Embedding\n",
        "from keras.models import Model\n",
        "\n",
        "EMBEDDING_DIM = 50\n",
        "N_CLASSES = 2\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)(sequence_input)\n",
        "\n",
        "average = GlobalAveragePooling1D()(embedded_sequences)\n",
        "predictions = Dense(N_CLASSES, activation='softmax')(average)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "59y4Uv5UrQxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d472568d-b2e4-4136-bbfc-cc64815a9755"
      },
      "source": [
        "history=model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=10, batch_size=128, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 - 14s - loss: 0.6481 - acc: 0.6907 - val_loss: 0.5568 - val_acc: 0.7989 - 14s/epoch - 272ms/step\n",
            "Epoch 2/10\n",
            "53/53 - 5s - loss: 0.5848 - acc: 0.7149 - val_loss: 0.5122 - val_acc: 0.7989 - 5s/epoch - 87ms/step\n",
            "Epoch 3/10\n",
            "53/53 - 4s - loss: 0.5534 - acc: 0.7151 - val_loss: 0.5144 - val_acc: 0.7989 - 4s/epoch - 74ms/step\n",
            "Epoch 4/10\n",
            "53/53 - 3s - loss: 0.5210 - acc: 0.7232 - val_loss: 0.5173 - val_acc: 0.8084 - 3s/epoch - 47ms/step\n",
            "Epoch 5/10\n",
            "53/53 - 2s - loss: 0.4874 - acc: 0.7506 - val_loss: 0.5115 - val_acc: 0.8084 - 2s/epoch - 41ms/step\n",
            "Epoch 6/10\n",
            "53/53 - 1s - loss: 0.4505 - acc: 0.7809 - val_loss: 0.5137 - val_acc: 0.7922 - 736ms/epoch - 14ms/step\n",
            "Epoch 7/10\n",
            "53/53 - 1s - loss: 0.4101 - acc: 0.8156 - val_loss: 0.5271 - val_acc: 0.7692 - 1s/epoch - 28ms/step\n",
            "Epoch 8/10\n",
            "53/53 - 1s - loss: 0.3700 - acc: 0.8519 - val_loss: 0.5137 - val_acc: 0.7719 - 1s/epoch - 24ms/step\n",
            "Epoch 9/10\n",
            "53/53 - 2s - loss: 0.3312 - acc: 0.8817 - val_loss: 0.5043 - val_acc: 0.7733 - 2s/epoch - 29ms/step\n",
            "Epoch 10/10\n",
            "53/53 - 1s - loss: 0.2960 - acc: 0.9013 - val_loss: 0.5238 - val_acc: 0.7530 - 544ms/epoch - 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "K-MqP7zSrQxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b8fdc9-1151-4f18-f990-3a539621dab3"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_casses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ESQJVKkgPMz",
        "outputId": "df560e21-c781-4e86-f556-81b78b6bcc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),test_casses,digits=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAfzIUsDgODs",
        "outputId": "a5fda119-6eef-4042-bc5b-484aacb0adf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.86512   0.94964   0.90541      1648\n",
            "           1    0.56545   0.30682   0.39779       352\n",
            "\n",
            "    accuracy                        0.83650      2000\n",
            "   macro avg    0.71528   0.62823   0.65160      2000\n",
            "weighted avg    0.81238   0.83650   0.81607      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ecciDY9arQxe"
      },
      "source": [
        "### Building more complex models\n",
        "\n",
        "**Exercise**\n",
        "- From the previous template, build more complex models using:\n",
        "  - 1d convolution and 1d maxpooling. Note that you will still need a GloabalAveragePooling or Flatten after the convolutions\n",
        "  - Recurrent neural networks through LSTM (you will need to reduce sequence length before)\n",
        "  \n",
        "  \n",
        "<img src=\"https://m2dsupsdlclass.github.io/lectures-labs/slides/06_deep_nlp/images/unrolled_rnn_one_output_2.svg\" style=\"width: 600px;\" />\n",
        "\n",
        "**Bonus**\n",
        "- You may try different architectures with:\n",
        "  - more intermediate layers, combination of dense, conv, recurrent\n",
        "  - different recurrent (GRU, RNN)\n",
        "  - bidirectional LSTMs\n",
        "\n",
        "Note: The goal is to build working models rather than getting better test accuracy. To achieve much better results, we'd need more computation time and data quantity. Build your model, and verify that they converge to OK results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XXisPg6ND8Y"
      },
      "source": [
        "# solutions lstm.py\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Embedding, Flatten, Dense, Dropout\n",
        "EMBEDDING_DIM = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YuumzzWZrQxf"
      },
      "source": [
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# LSTM layer with a hidden size of 64\n",
        "x = LSTM(64,dropout=0.2)(embedded_sequences)\n",
        "x = Dense(30) (x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# You will get large speedups with these models by using a GPU\n",
        "# The model might take a lot of time to converge, and even more\n",
        "# if you add dropout (needed to prevent overfitting)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdrNvZ5D8ojO",
        "outputId": "6fdcb7d0-953d-45c7-f74c-eea5b98c1246"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 25)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 25, 300)           6000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                93440     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 30)                1950      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 62        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,095,452\n",
            "Trainable params: 6,095,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jtm2uIB30v0",
        "outputId": "af25a356-9136-4214-aa8a-63da316cfd7f"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=4, validation_split=0.1,\n",
        "          batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "53/53 [==============================] - 15s 162ms/step - loss: 0.5920 - acc: 0.7142 - val_loss: 0.5240 - val_acc: 0.7800\n",
            "Epoch 2/4\n",
            "53/53 [==============================] - 6s 106ms/step - loss: 0.3813 - acc: 0.8339 - val_loss: 0.5805 - val_acc: 0.7395\n",
            "Epoch 3/4\n",
            "53/53 [==============================] - 5s 88ms/step - loss: 0.1365 - acc: 0.9499 - val_loss: 0.5605 - val_acc: 0.7679\n",
            "Epoch 4/4\n",
            "53/53 [==============================] - 4s 71ms/step - loss: 0.0530 - acc: 0.9828 - val_loss: 0.9357 - val_acc: 0.6910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f511ebb87f0>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkBlX7d-3y-p",
        "outputId": "97e0bda7-d2ae-4199-a481-449e31def4f8"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),test_casses,digits=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.87129   0.74757   0.80470      1648\n",
            "           1    0.29010   0.48295   0.36247       352\n",
            "\n",
            "    accuracy                        0.70100      2000\n",
            "   macro avg    0.58069   0.61526   0.58359      2000\n",
            "weighted avg    0.76900   0.70100   0.72687      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ewXMxJv5rQxh"
      },
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# A 1D convolution with 128 output channels\n",
        "x = Conv1D(128, 2, activation='relu')(embedded_sequences)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "# A 1D convolution with 64 output channels\n",
        "x = Conv1D(64, 2, activation='relu')(x)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GicNxZ65Vj_",
        "outputId": "583e31ab-7229-4c8b-ed14-28212f77b3c9"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=4, validation_split=0.1,\n",
        "          batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "53/53 [==============================] - 13s 137ms/step - loss: 0.5898 - acc: 0.7076 - val_loss: 0.5262 - val_acc: 0.7989\n",
            "Epoch 2/4\n",
            "53/53 [==============================] - 4s 66ms/step - loss: 0.4532 - acc: 0.7751 - val_loss: 0.5586 - val_acc: 0.6923\n",
            "Epoch 3/4\n",
            "53/53 [==============================] - 4s 77ms/step - loss: 0.1605 - acc: 0.9468 - val_loss: 0.6593 - val_acc: 0.6734\n",
            "Epoch 4/4\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.0317 - acc: 0.9937 - val_loss: 0.7621 - val_acc: 0.6991\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f511f61b940>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiNX-sUr5WJb",
        "outputId": "6287a7ba-1cbb-4d07-bf9e-eab5d5755daf"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),test_casses,digits=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.86738   0.83738   0.85211      1648\n",
            "           1    0.34474   0.40057   0.37057       352\n",
            "\n",
            "    accuracy                        0.76050      2000\n",
            "   macro avg    0.60606   0.61897   0.61134      2000\n",
            "weighted avg    0.77540   0.76050   0.76736      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2mbEd2MMyde"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True) (sequence_input)\n",
        "\n",
        "# 1D convolution with 64 output channels\n",
        "x = Conv1D(128, 2)(embedded_sequences)\n",
        "# MaxPool divides the length of the sequence by 5\n",
        "x = MaxPooling1D(2)(x)\n",
        "# LSTM layer with a hidden size of 64\n",
        "x = LSTM(64)(x)\n",
        "x = Dense(30) (x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "d_DgldjvrQxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a42480-4630-4eaa-fab2-e6e8c1ca0135"
      },
      "source": [
        "model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=5, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "53/53 [==============================] - 10s 131ms/step - loss: 0.6002 - acc: 0.7085 - val_loss: 0.5481 - val_acc: 0.7962\n",
            "Epoch 2/5\n",
            "53/53 [==============================] - 4s 79ms/step - loss: 0.4143 - acc: 0.8166 - val_loss: 0.6651 - val_acc: 0.6721\n",
            "Epoch 3/5\n",
            "53/53 [==============================] - 3s 51ms/step - loss: 0.1458 - acc: 0.9492 - val_loss: 0.5957 - val_acc: 0.7530\n",
            "Epoch 4/5\n",
            "53/53 [==============================] - 3s 55ms/step - loss: 0.0416 - acc: 0.9889 - val_loss: 0.9453 - val_acc: 0.7233\n",
            "Epoch 5/5\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 0.0122 - acc: 0.9969 - val_loss: 1.1004 - val_acc: 0.7449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5121271c10>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Nu2QveWRtQNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5f98a4-84ca-4525-d486-891bb4e7496d"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),test_casses,digits=5))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.86361   0.86833   0.86596      1648\n",
            "           1    0.36735   0.35795   0.36259       352\n",
            "\n",
            "    accuracy                        0.77850      2000\n",
            "   macro avg    0.61548   0.61314   0.61428      2000\n",
            "weighted avg    0.77627   0.77850   0.77737      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Yg5PujZArQxp"
      },
      "source": [
        "### Loading pre-trained embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDwTwcG3QZiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401b9829-cf84-442d-ec67-09132093bf18"
      },
      "source": [
        "import os.path as op\n",
        "import gzip\n",
        "import shutil\n",
        "from urllib.request import urlretrieve\n",
        "# Get pretrained FastText Embeddings\n",
        "URL_REPRESENTATIONS = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz\"\n",
        "ZIP_REPRESENTATIONS = \"cc.it.300.vec.gz\"\n",
        "FILE_REPRESENTATIONS = \"cc.it.300.vec\"\n",
        "\n",
        "if not op.exists(ZIP_REPRESENTATIONS):\n",
        "    print('Downloading from %s to %s...' % (URL_REPRESENTATIONS, ZIP_REPRESENTATIONS))\n",
        "    urlretrieve(URL_REPRESENTATIONS, './' + ZIP_REPRESENTATIONS)\n",
        "    \n",
        "with gzip.open(ZIP_REPRESENTATIONS, 'rb') as f_in:\n",
        "    with open(FILE_REPRESENTATIONS, 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz to cc.it.300.vec.gz...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "s2ruhdN7rQxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23fa607-3a88-4424-c345-cc8fd19372ac"
      },
      "source": [
        "embeddings_index = {}\n",
        "embeddings_vectors = []\n",
        "f = open('cc.it.300.vec', 'rb')\n",
        "\n",
        "word_idx = 0\n",
        "i = 0\n",
        "for line in f:\n",
        "    if i != 0:\n",
        "      values = line.decode('utf-8').split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = word_idx\n",
        "      embeddings_vectors.append(vector)\n",
        "      word_idx = word_idx + 1\n",
        "    i = i+1\n",
        "f.close()\n",
        "\n",
        "inv_index = {v: k for k, v in embeddings_index.items()}\n",
        "print(\"found %d different words in the file\" % word_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 2000000 different words in the file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "155s4vaVrQxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc993f8-dbb9-449b-a09f-53ff069cd2bd"
      },
      "source": [
        "# Stack all embeddings in a large numpy array\n",
        "embeddings = np.vstack(embeddings_vectors)\n",
        "\n",
        "print(embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GL_Hxg5RrQxv"
      },
      "source": [
        "def get_emb(word):\n",
        "    idx = embeddings_index.get(word)\n",
        "    if idx is None:\n",
        "        return None\n",
        "    else:\n",
        "        return embeddings[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wPLE9E9ZrQys"
      },
      "source": [
        "### Using pre-trained embeddings in our model\n",
        "\n",
        "We want to use these pre-trained embeddings for transfer learning. This process is rather similar than transfer learning in image recognition: the features learnt on words might help us bootstrap the learning process, and increase performance if we don't have enough training data.\n",
        "- We initialize embedding matrix from the model with embeddings:\n",
        " - take all words from our 20 Newgroup vocabulary (`MAX_NB_WORDS = 20000`), and look up their embedding \n",
        " - place the Glove embedding at the corresponding index in the matrix\n",
        " - if the word is not in the vocabulary, we only place zeros in the matrix\n",
        "- We may fix these embeddings or fine-tune them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "OgMfL-eZrQys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545b3b9a-d562-4c00-edef-f4b711ce374f"
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# prepare embedding matrix\n",
        "nb_words_in_matrix = 0\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NB_WORDS:\n",
        "        continue\n",
        "    embedding_vector = get_emb(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        nb_words_in_matrix = nb_words_in_matrix + 1\n",
        "        \n",
        "print(\"added %d words in the embedding matrix\" % nb_words_in_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added 13368 words in the embedding matrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHcT5YfajuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa14b49-4258-45f2-f9c7-7585fe0dfe75"
      },
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "V93Ik4QWrQyv"
      },
      "source": [
        "Build a layer with pre-trained embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MhZZdW72rQyy"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "pretrained_embedding_layer = Embedding(\n",
        "    MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LENGTH\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8Y7iUkbwrQzE"
      },
      "source": [
        "### A model with pre-trained Embeddings\n",
        "\n",
        "Average word embeddings pre-trained with Glove / Word2Vec usually works suprisingly well. However, when averaging more than `10-15` words, the resulting vector becomes too noisy and classification performance is degraded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "gG9dWAhorQzH"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Input, Dense\n",
        "from keras.models import Model\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "emb = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,weights=[embedding_matrix],input_length=MAX_SEQUENCE_LENGTH)(sequence_input)\n",
        "\n",
        "rec = LSTM(units=128,return_sequences = True)(emb)\n",
        "flat = Flatten()(rec)\n",
        "dense = Dense(200,activation='sigmoid') (flat)\n",
        "predictions = Dense(2, activation='softmax')(dense)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "\n",
        "# We don't want to fine-tune embeddings\n",
        "model.layers[1].trainable=False\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_eSJiYdd_q6"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "#plot_model(model)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lMt5THcJrQza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9b2aaf-e338-4e4a-8dba-6744926d0f7a"
      },
      "source": [
        "model.fit(x_train, y_train, validation_split=0.1,\n",
        "          epochs=10, batch_size=128)\n",
        "\n",
        "# Note, on this type of task, this technique will \n",
        "# degrade results as we train much less parameters\n",
        "# and we average a large number pre-trained embeddings.\n",
        "# You will notice much less overfitting then!\n",
        "# Using convolutions / LSTM will help\n",
        "# It is also advisable to treat seperately pre-trained\n",
        "# embeddings and words out of vocabulary."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "53/53 [==============================] - 10s 17ms/step - loss: 0.5981 - acc: 0.6961 - val_loss: 0.5842 - val_acc: 0.6910\n",
            "Epoch 2/10\n",
            "53/53 [==============================] - 0s 8ms/step - loss: 0.5244 - acc: 0.7523 - val_loss: 0.4527 - val_acc: 0.8124\n",
            "Epoch 3/10\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.4959 - acc: 0.7716 - val_loss: 0.4863 - val_acc: 0.7827\n",
            "Epoch 4/10\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.4757 - acc: 0.7799 - val_loss: 0.6217 - val_acc: 0.6896\n",
            "Epoch 5/10\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4570 - acc: 0.7925 - val_loss: 0.5556 - val_acc: 0.7409\n",
            "Epoch 6/10\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.4368 - acc: 0.8033 - val_loss: 0.5512 - val_acc: 0.7598\n",
            "Epoch 7/10\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.4184 - acc: 0.8154 - val_loss: 0.4863 - val_acc: 0.7881\n",
            "Epoch 8/10\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.4127 - acc: 0.8118 - val_loss: 0.4955 - val_acc: 0.7800\n",
            "Epoch 9/10\n",
            "53/53 [==============================] - 0s 7ms/step - loss: 0.3891 - acc: 0.8334 - val_loss: 0.6746 - val_acc: 0.7072\n",
            "Epoch 10/10\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 0.3728 - acc: 0.8357 - val_loss: 0.6871 - val_acc: 0.6896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61b3f86580>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WKZdqUlXHle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7640d1c-86c8-4f47-ac72-6f47cf7ceeea"
      },
      "source": [
        "output_test = model.predict(x_test)\n",
        "test_casses = np.argmax(output_test, axis=-1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.array(test[\"opos\"]),test_casses,digits=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.87435   0.71359   0.78583      1648\n",
            "           1    0.27939   0.51989   0.36346       352\n",
            "\n",
            "    accuracy                        0.67950      2000\n",
            "   macro avg    0.57687   0.61674   0.57464      2000\n",
            "weighted avg    0.76964   0.67950   0.71150      2000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}